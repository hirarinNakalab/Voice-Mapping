diff --git a/Speaker-Embeddings/README.md b/Speaker-Embeddings/README.md
deleted file mode 100644
index 91cd081..0000000
--- a/Speaker-Embeddings/README.md
+++ /dev/null
@@ -1,6 +0,0 @@
-# Speaker-Embeddings
-Feedforward network generating speaker embeddings 
-
-## dependency
-- python3.7
-
diff --git a/Speaker-Embeddings/config/config.yaml b/Speaker-Embeddings/config/config.yaml
deleted file mode 100644
index 784f9e6..0000000
--- a/Speaker-Embeddings/config/config.yaml
+++ /dev/null
@@ -1,28 +0,0 @@
-device: "cpu" # cuda or cpu
-training: !!bool "true"
-actors_data: 'data/actors_voice'
----
-data:
-    nonpara_path: 'data/nonpara'
-    parallel_path: 'data/parallel'
-    sim_csv_path: 'data/speaker_similarity_{}.csv'
-    non_para_contents: 'nonpara30/wav24kHz16bit'
-    parallel_contents: 'parallel100/wav24kHz16bit'
-    sr: 16000
----
-train:
-    M : 4 #Number of utterances per speaker in batch
-    num_workers: 0 #number of workers for dataloader
-    num_input_size: 5
-    num_mel_dim: 39
-    lr: 0.01 
-    iteration: 700 #Max training speaker epoch
-    log_interval: 1 #Epochs before printing progress
-    checkpoint_interval: 100 #Save model after x speaker epochs
-    checkpoint_dir: 'model/ckpt'
-    restore: !!bool "false" #Resume training from previous model path
----
-test:
-    M : 1 #Number of utterances per speaker
-    num_workers: 0 #number of workers for dataloader
-    simmat_dir: 'output'
diff --git a/Speaker-Embeddings/create_simmat.py b/Speaker-Embeddings/create_simmat.py
deleted file mode 100644
index d357039..0000000
--- a/Speaker-Embeddings/create_simmat.py
+++ /dev/null
@@ -1,72 +0,0 @@
-import glob
-import os
-import sys
-sys.path.append("./")
-import random
-
-import torch
-import pandas as pd
-import warnings
-warnings.simplefilter('ignore')
-
-from hparam import hparam as hp
-from model import FFNet
-from dataloader import audio_to_dvector, utters_to_dvectors
-from preprocess import get_speakers_dict
-
-
-
-
-def gausian_kernel(di, dj, gamma=1.0):
-    diff = di - dj
-    norm = torch.norm(diff, p=2, dim=1, keepdim=True)
-    return torch.exp(-gamma * norm)
-
-def main(gender="female", user_audio=""):
-    movel_path = os.path.join(os.path.dirname(__file__),
-                              hp.train.checkpoint_dir,
-                              f"final_epoch_{hp.train.iteration}.model")
-
-    device = torch.device(hp.device)
-
-    net = FFNet().to(device)
-    net.load_state_dict(torch.load(movel_path))
-    net.eval()
-
-    d_vectors, speakers = [], []
-    user_name = "actors"
-    search_path = os.path.join(os.path.dirname(__file__), hp.actors_data, '*.wav')
-    for wavfile in glob.glob(search_path):
-        speakers.append(os.path.basename(wavfile).split(".")[0])
-        d_vectors.append(audio_to_dvector(wavfile, net, device))
-
-    if user_audio != "":
-        user_name = os.path.basename(user_audio).split(".")[0]
-        speakers.append(user_name)
-        d_vectors.append(audio_to_dvector(user_audio, net, device))
-
-    Ns = len(d_vectors)
-    utter = torch.stack(d_vectors)
-    ks = [gausian_kernel(utter, utter[i]) for i in range(Ns)]
-    gram_matrix = torch.cat(ks, dim=1)
-    gram_matrix = gram_matrix.cpu().detach().numpy()
-
-    simmat = pd.DataFrame(data=gram_matrix, index=speakers, columns=None)
-
-    output_dir = os.path.join(os.path.dirname(__file__), hp.test.simmat_dir)
-    os.makedirs(output_dir, exist_ok=True)
-    fn = os.path.join(output_dir, f"simmat_{user_name}.csv")
-    simmat.to_csv(fn, index=True, header=False)
-    print("output: ", fn)
-
-
-
-if __name__ == "__main__":
-    if len(sys.argv) > 2:
-        user_audio = sys.argv[1]
-        gender = sys.argv[2]
-    else:
-        user_audio = ""
-        gender = "female"
-
-    main(gender=gender, user_audio=user_audio)
\ No newline at end of file
diff --git a/Speaker-Embeddings/data/actors_voice/.gitkeep b/Speaker-Embeddings/data/actors_voice/.gitkeep
deleted file mode 100644
index e69de29..0000000
diff --git a/Speaker-Embeddings/data/actors_voice/akane.wav b/Speaker-Embeddings/data/actors_voice/akane.wav
deleted file mode 100755
index 1b2d517..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/akane.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/ami.wav b/Speaker-Embeddings/data/actors_voice/ami.wav
deleted file mode 100755
index ce0b253..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/ami.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/anna.wav b/Speaker-Embeddings/data/actors_voice/anna.wav
deleted file mode 100755
index 96e3b83..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/anna.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/arisa.wav b/Speaker-Embeddings/data/actors_voice/arisa.wav
deleted file mode 100755
index a5d370d..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/arisa.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/ayumu.wav b/Speaker-Embeddings/data/actors_voice/ayumu.wav
deleted file mode 100755
index 446853b..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/ayumu.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/azusa.wav b/Speaker-Embeddings/data/actors_voice/azusa.wav
deleted file mode 100755
index 4ea3fca..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/azusa.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/chihaya.wav b/Speaker-Embeddings/data/actors_voice/chihaya.wav
deleted file mode 100755
index 25a7147..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/chihaya.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/emiri-.wav b/Speaker-Embeddings/data/actors_voice/emiri-.wav
deleted file mode 100755
index 121e92c..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/emiri-.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/erena.wav b/Speaker-Embeddings/data/actors_voice/erena.wav
deleted file mode 100755
index 2beee11..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/erena.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/haruka.wav b/Speaker-Embeddings/data/actors_voice/haruka.wav
deleted file mode 100755
index cb19c4b..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/haruka.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/hibiki.wav b/Speaker-Embeddings/data/actors_voice/hibiki.wav
deleted file mode 100755
index a5f8eeb..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/hibiki.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/hinata.wav b/Speaker-Embeddings/data/actors_voice/hinata.wav
deleted file mode 100755
index d9f3ebd..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/hinata.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/actors_voice/huuka.wav b/Speaker-Embeddings/data/actors_voice/huuka.wav
deleted file mode 100755
index dbbeb96..0000000
Binary files a/Speaker-Embeddings/data/actors_voice/huuka.wav and /dev/null differ
diff --git a/Speaker-Embeddings/data/jvs_pararell.bash b/Speaker-Embeddings/data/jvs_pararell.bash
deleted file mode 100644
index 1deb7ac..0000000
--- a/Speaker-Embeddings/data/jvs_pararell.bash
+++ /dev/null
@@ -1,52 +0,0 @@
-#!/usr/bin/env bash
-
-JVSDIR=../../japanese_speech_corpus/jvs_ver1/
-OUTDIR=../../japanese_speech_corpus/jvs_hiho_ver1/
-
-mkdir $OUTDIR
-
-# link all wave file
-for speaker in jvs{001..100}; do
-    echo $speaker
-    for corpus in falset10 nonpara30 parallel100 whisper10; do
-        mkdir -p $OUTDIR/$speaker/$corpus/wav24kHz16bit
-        find $JVSDIR/$speaker/$corpus/wav24kHz16bit -name '*.wav' | parallel ln {} $OUTDIR/$speaker/$corpus/wav24kHz16bit/{/}
-    done
-done
-
-# move known mistake
-mv $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_021.wav $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_022.wav
-mv $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_020.wav $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_021.wav
-mv $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_019.wav $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_020.wav
-mv $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_018.wav $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_019.wav
-mv $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_017.wav $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_018.wav
-mv $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_016.wav $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_017.wav
-mv $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_015.wav $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_016.wav
-
-# remove known mistake
-rm $OUTDIR/jvs009/parallel100/wav24kHz16bit/VOICEACTRESS100_086.wav
-rm $OUTDIR/jvs009/parallel100/wav24kHz16bit/VOICEACTRESS100_095.wav
-rm $OUTDIR/jvs017/parallel100/wav24kHz16bit/VOICEACTRESS100_082.wav
-rm $OUTDIR/jvs018/parallel100/wav24kHz16bit/VOICEACTRESS100_072.wav
-rm $OUTDIR/jvs022/parallel100/wav24kHz16bit/VOICEACTRESS100_047.wav
-rm $OUTDIR/jvs024/parallel100/wav24kHz16bit/VOICEACTRESS100_088.wav
-rm $OUTDIR/jvs036/parallel100/wav24kHz16bit/VOICEACTRESS100_057.wav
-rm $OUTDIR/jvs038/parallel100/wav24kHz16bit/VOICEACTRESS100_006.wav
-rm $OUTDIR/jvs038/parallel100/wav24kHz16bit/VOICEACTRESS100_041.wav
-rm $OUTDIR/jvs043/parallel100/wav24kHz16bit/VOICEACTRESS100_085.wav
-rm $OUTDIR/jvs047/parallel100/wav24kHz16bit/VOICEACTRESS100_085.wav
-rm $OUTDIR/jvs048/parallel100/wav24kHz16bit/VOICEACTRESS100_043.wav
-rm $OUTDIR/jvs048/parallel100/wav24kHz16bit/VOICEACTRESS100_076.wav
-rm $OUTDIR/jvs051/parallel100/wav24kHz16bit/VOICEACTRESS100_025.wav
-rm $OUTDIR/jvs055/parallel100/wav24kHz16bit/VOICEACTRESS100_056.wav
-rm $OUTDIR/jvs055/parallel100/wav24kHz16bit/VOICEACTRESS100_076.wav
-rm $OUTDIR/jvs055/parallel100/wav24kHz16bit/VOICEACTRESS100_099.wav
-rm $OUTDIR/jvs058/parallel100/wav24kHz16bit/VOICEACTRESS100_014.wav
-rm $OUTDIR/jvs059/parallel100/wav24kHz16bit/VOICEACTRESS100_061.wav
-rm $OUTDIR/jvs059/parallel100/wav24kHz16bit/VOICEACTRESS100_064.wav
-rm $OUTDIR/jvs059/parallel100/wav24kHz16bit/VOICEACTRESS100_066.wav
-rm $OUTDIR/jvs059/parallel100/wav24kHz16bit/VOICEACTRESS100_074.wav
-rm $OUTDIR/jvs060/parallel100/wav24kHz16bit/VOICEACTRESS100_082.wav
-rm $OUTDIR/jvs074/parallel100/wav24kHz16bit/VOICEACTRESS100_062.wav
-rm $OUTDIR/jvs098/parallel100/wav24kHz16bit/VOICEACTRESS100_060.wav
-rm $OUTDIR/jvs098/parallel100/wav24kHz16bit/VOICEACTRESS100_099.wav
\ No newline at end of file
diff --git a/Speaker-Embeddings/data/speaker_similarity_female.csv b/Speaker-Embeddings/data/speaker_similarity_female.csv
deleted file mode 100755
index 6846195..0000000
--- a/Speaker-Embeddings/data/speaker_similarity_female.csv
+++ /dev/null
@@ -1,51 +0,0 @@
-jvs002,3,-1.5,0.5,-1,-1.6,-1,-0.6,-0.5,-0.7,0.1,-0.1,-0.9,0.2,-0.7,-0.3,0.5,-0.6,-0.4,-0.9,-0.1,-0.6,0.7,0,-0.4,-0.2,-1,-1.9,-0.5,-1.2,-0.3,0,0.3,-0.6,0.4,0.1,-1.3,-1.3,-0.6,-0.3,0.3,-1.5,-1.2,-1.5,-0.2,-0.9,-0.7,-0.5,-1.6,-0.7,-0.2,0.2
-jvs004,-1.5,3,-1.6,-1.8,-0.1,-1.2,0.4,-2,-0.8,-1,-1.5,-1.1,-1.3,0.9,-1.2,-0.9,-0.9,-0.2,-1.5,-0.2,-1.1,-1.9,-1.6,0.2,-0.4,0.6,-2.2,-1.6,-2,-1.8,-0.9,-0.2,-0.6,-0.7,-1.6,-1.4,-0.3,-0.8,-1.6,-1.4,-1.7,-0.7,-1.7,-1.6,-0.2,-1.6,-1.4,0.3,-0.6,-1.2,-1.3
-jvs007,0.5,-1.6,3,-0.7,-2,-1,-1.3,-0.6,-2,-0.6,-0.1,-1.3,0,-1.3,-1,-1.8,-0.9,-1.1,-2.4,-0.5,-0.6,-1.5,-0.4,0,-0.4,-0.7,-0.8,-0.2,-0.5,-1.5,-0.4,-0.7,-1.2,-0.5,0.2,-1,-1.4,-0.8,-0.5,0.4,-0.5,-0.1,-1,-0.9,-0.7,-1.2,0.1,-2.5,-0.9,-1.2,-0.3
-jvs008,-1,-1.8,-0.7,3,-2.1,-2,-1.5,1.2,-1.3,-1.1,-0.6,-1.8,-0.5,-1,0.3,-1.1,-0.6,-0.7,-1.2,-0.5,0,-0.1,-0.7,-1.3,-0.6,-1.8,-1.4,0.7,-0.5,-1,-1,-2.1,-1,-1,-2.1,-1.7,-1.3,-1.1,-0.5,-0.2,-0.4,-1.7,-1.8,-2.1,-1,-1.4,-1.5,-1.6,-0.9,-1,-1.3
-jvs010,-1.6,-0.1,-2,-2.1,3,0.8,-1.5,-1.4,-0.5,-2.2,-0.6,-1.4,-1.1,-0.6,-1.5,-2.3,-1.8,-1.3,-1,-0.9,-1.9,-2.2,-2.9,-1.5,-2.1,0,-2.9,-1.9,-1.5,-2.5,-1.5,-2.3,-1,-2.6,-2.9,-2.3,-1.4,-0.2,-2.3,-1.7,-1.6,-0.4,-1.4,-1.3,-2.3,-1.7,-2.6,-1,-1,-1.9,-2.4
-jvs014,-1,-1.2,-1,-2,0.8,3,-0.8,-2.2,-0.6,-2.1,-1.1,-1.9,-1.1,-0.2,-2,-3,-2.8,-1.6,-0.8,-2.3,-0.7,-1.5,-2.2,-0.7,-1,-1.5,-1.9,-2.2,-2.2,-1.8,-1.3,-1.4,-1.4,-2,-1.6,-1.3,-2.1,-1.7,-0.9,-2.5,-1.7,-0.4,-2.7,-1.9,-0.6,-2.7,-2.2,-0.1,-1.2,-1.9,-1.5
-jvs015,-0.6,0.4,-1.3,-1.5,-1.5,-0.8,3,-1.1,-0.9,-1.4,-0.1,0,-0.3,-1,-0.9,-1.4,-0.3,-0.7,0.9,-0.6,-1.3,-1.6,-0.9,0,-0.3,-1,-1.1,-1.5,-1.5,-1,-1.3,-0.5,-1,0,-0.7,-0.5,0.3,0,-2.1,-1.2,-1.3,-0.7,-1.2,-1.5,-0.3,-1,-1.7,-0.4,-1.4,-0.7,-0.7
-jvs016,-0.5,-2,-0.6,1.2,-1.4,-2.2,-1.1,3,-1.1,-0.7,-1.3,-1.5,-0.9,-1.3,-1,-0.8,-0.3,-1.1,-1.1,-0.2,-0.8,-0.3,-0.6,-1.1,-0.9,-0.1,-0.7,-0.4,-0.3,-0.6,-1,-0.8,-0.7,-0.7,-0.3,-0.4,-0.3,-0.7,-0.4,-1.3,-0.8,-2,-1.1,-1.1,-1.8,-1.9,-0.1,-1.3,-1.6,0.4,-1.3
-jvs017,-0.7,-0.8,-2,-1.3,-0.5,-0.6,-0.9,-1.1,3,-0.1,-1.7,-1.3,-0.5,-2.2,-1.4,-1.7,-1.1,-1.2,-0.3,-0.6,-2.2,-0.7,-1.5,-0.4,-1.5,-0.3,-1.2,-1.8,-1.6,-1.4,-0.9,-1.4,-0.6,-0.6,-0.9,-0.9,-0.1,-0.7,-1.7,-1.6,-2.4,-1.3,-0.8,-0.9,-1.6,-1.6,-1.2,-0.9,-1.3,-0.8,-2.3
-jvs018,0.1,-1,-0.6,-1.1,-2.2,-2.1,-1.4,-0.7,-0.1,3,-0.6,-1.2,0.7,-2,-1.7,-0.7,-1.3,-0.6,-1.2,-0.6,-0.9,-0.9,-0.2,-2,-1,-0.7,-2.2,-0.9,-1.1,-0.9,-0.5,-2.1,-0.2,-0.9,-0.7,-0.2,-0.3,-0.3,0,-0.3,-0.6,-0.8,-0.9,-0.1,-0.7,-1.3,-0.3,-2.3,-0.5,-0.2,-1.1
-jvs019,-0.1,-1.5,-0.1,-0.6,-0.6,-1.1,-0.1,-1.3,-1.7,-0.6,3,0.3,-0.6,-0.6,-0.9,-0.8,-0.5,-2.2,-0.9,-0.2,-0.4,-0.3,-0.5,-0.8,-1.2,1.2,-1,-0.8,-1.1,-1.2,0.8,-0.8,-0.7,-0.2,-1.7,-1,-0.3,-0.1,-0.6,0.1,-1.1,-1.1,-0.6,-0.2,-0.5,-0.6,-1.3,-2.5,-0.4,-1.2,1.3
-jvs024,-0.9,-1.1,-1.3,-1.8,-1.4,-1.9,0,-1.5,-1.3,-1.2,0.3,3,0.4,-0.2,-0.5,-0.3,0.1,-1.6,0.3,-1,0.4,-0.4,-0.6,0.3,-0.7,-1.3,-0.8,-0.8,-2,-1.4,-0.8,-0.2,-0.8,-0.4,-0.3,0.1,-0.3,-1.2,-0.8,-1.4,-1,-0.7,-0.8,-0.3,-0.2,-1.2,-0.7,-0.3,-1.1,-0.4,-0.3
-jvs025,0.2,-1.3,0,-0.5,-1.1,-1.1,-0.3,-0.9,-0.5,0.7,-0.6,0.4,3,-0.8,-1.4,-0.3,-1.8,0,-0.3,-0.9,-0.5,-0.2,-1,-1.1,-1.3,-1.7,-0.7,-0.7,-0.4,-0.7,-0.7,-0.2,-0.1,-0.7,-0.7,-0.9,-0.7,-0.1,1.3,0.1,-1,-0.7,-1.6,-0.6,-0.4,-0.8,-1,-0.5,-0.3,-0.2,-0.8
-jvs026,-0.7,0.9,-1.3,-1,-0.6,-0.2,-1,-1.3,-2.2,-2,-0.6,-0.2,-0.8,3,-0.1,-0.4,-0.6,-1.7,-0.5,-1.3,0.6,-0.3,-0.6,0.1,-1.9,-1.6,-1.3,-1.8,-1.3,-1.8,-1.1,-1,0,0.1,-1.1,-0.6,-0.9,-1.6,-0.9,-1,0,0,-1.5,0,-0.8,-1.3,-0.8,-2.1,0.2,-0.4,-1.3
-jvs027,-0.3,-1.2,-1,0.3,-1.5,-2,-0.9,-1,-1.4,-1.7,-0.9,-0.5,-1.4,-0.1,3,-0.4,0.5,0,-0.4,-1.2,-0.3,1.2,-1.3,-1,-1.4,-1.6,-1,-0.1,-0.9,-1,-1.3,-1.2,-0.8,-1.2,-0.9,-1.1,-1.3,-1.7,-1.2,-0.9,0,-0.9,-1.4,0,-1.3,-0.8,-0.4,-1.8,-2,0.2,-1.9
-jvs029,0.5,-0.9,-1.8,-1.1,-2.3,-3,-1.4,-0.8,-1.7,-0.7,-0.8,-0.3,-0.3,-0.4,-0.4,3,-0.5,-0.3,-1.2,0.4,-0.6,-0.9,-0.1,-0.9,-0.3,-1.3,-1.2,-0.8,-2,0,0.5,-0.3,-0.7,-0.5,-0.2,-1.3,0.3,-0.7,-0.4,-0.5,-1,-1.2,0.2,0.5,-0.5,-0.1,0,-1.5,-1.1,0.8,0
-jvs030,-0.6,-0.9,-0.9,-0.6,-1.8,-2.8,-0.3,-0.3,-1.1,-1.3,-0.5,0.1,-1.8,-0.6,0.5,-0.5,3,-0.8,-0.5,-0.5,-0.6,-0.1,-1.1,-0.4,-0.7,-0.1,-2.2,-1.8,-1.6,-1.6,-1.4,0.2,-1.3,0.4,0.1,-0.4,-0.7,-1.5,-1.3,-1.1,-1.5,-1.2,-0.8,-1.2,-0.8,-2.1,-0.7,-1.7,-2.3,-1.2,-1.8
-jvs035,-0.4,-0.2,-1.1,-0.7,-1.3,-1.6,-0.7,-1.1,-1.2,-0.6,-2.2,-1.6,0,-1.7,0,-0.3,-0.8,3,-1.1,0.2,-0.6,-0.4,-0.8,-0.5,0.1,-1.1,-1.5,0.3,0,-1.7,-1.2,-1.1,0.2,-0.6,-0.3,-1.3,0,-1.8,-0.5,-0.7,-0.8,-1.1,-0.6,-0.3,-1.1,-1.4,-1.7,-0.8,-0.8,-1.3,-0.9
-jvs036,-0.9,-1.5,-2.4,-1.2,-1,-0.8,0.9,-1.1,-0.3,-1.2,-0.9,0.3,-0.3,-0.5,-0.4,-1.2,-0.5,-1.1,3,-1,-1,0.3,-1.8,0.1,-1.7,-0.9,-2.6,-2.4,-2.5,-1.2,-1.6,0.2,0.9,-0.8,-0.6,-0.5,-0.6,-0.8,-2.5,-0.5,-2.4,-0.5,-1,-0.7,-0.8,-1.3,-1.3,-0.6,-2.1,-2.1,-1
-jvs038,-0.1,-0.2,-0.5,-0.5,-0.9,-2.3,-0.6,-0.2,-0.6,-0.6,-0.2,-1,-0.9,-1.3,-1.2,0.4,-0.5,0.2,-1,3,-1.1,-1.2,-0.4,-0.8,-0.2,0,-1,-1.2,0.3,-1.2,-0.5,-0.1,-0.6,0.2,-1.2,-0.5,-0.5,-0.4,-0.4,-0.8,0.3,0.2,-1,0.3,-0.7,-1.4,-0.9,-1.8,0,-0.7,0
-jvs039,-0.6,-1.1,-0.6,0,-1.9,-0.7,-1.3,-0.8,-2.2,-0.9,-0.4,0.4,-0.5,0.6,-0.3,-0.6,-0.6,-0.6,-1,-1.1,3,0.3,-1,0.6,-1.5,-0.6,-1.8,-1.1,-0.6,-1.3,-0.6,-0.6,-0.3,-0.3,-1.4,0.3,-0.5,-1.3,-1.2,-0.9,-1.4,0,-1,-0.6,-0.4,-1.5,-0.9,-0.8,-0.4,-0.7,0
-jvs040,0.7,-1.9,-1.5,-0.1,-2.2,-1.5,-1.6,-0.3,-0.7,-0.9,-0.3,-0.4,-0.2,-0.3,1.2,-0.9,-0.1,-0.4,0.3,-1.2,0.3,3,-1.7,-0.3,-0.6,-1.2,-1,-1,-1.6,-1.4,-0.9,-0.1,-0.6,-0.1,-0.3,-0.6,0.2,-2,0,-1,-1.1,-0.7,-1.1,-0.6,-0.9,-0.9,-1,-2,-1.3,-1,-1
-jvs043,0,-1.6,-0.4,-0.7,-2.9,-2.2,-0.9,-0.6,-1.5,-0.2,-0.5,-0.6,-1,-0.6,-1.3,-0.1,-1.1,-0.8,-1.8,-0.4,-1,-1.7,3,-0.2,0.8,-0.7,-1.1,-0.8,-0.4,-0.8,-0.3,-1.1,-0.8,-0.4,-0.5,-1.1,-1,-1,-0.8,-0.7,-0.7,-0.3,-0.7,-0.5,-1,0.4,-1.3,-2,-0.6,0.6,-0.4
-jvs051,-0.4,0.2,0,-1.3,-1.5,-0.7,0,-1.1,-0.4,-2,-0.8,0.3,-1.1,0.1,-1,-0.9,-0.4,-0.5,0.1,-0.8,0.6,-0.3,-0.2,3,-0.6,-0.4,-2,-2,-0.8,-1.8,-0.5,-0.8,-1,-0.1,-2.7,0,0,0,-0.8,-1.1,-0.7,-0.4,-1.4,-0.5,-0.8,-1.8,-2.7,-0.2,0.9,-0.3,-0.2
-jvs053,-0.2,-0.4,-0.4,-0.6,-2.1,-1,-0.3,-0.9,-1.5,-1,-1.2,-0.7,-1.3,-1.9,-1.4,-0.3,-0.7,0.1,-1.7,-0.2,-1.5,-0.6,0.8,-0.6,3,-0.3,-1.9,-0.5,-0.6,-0.3,-0.6,0.8,-0.3,-0.2,-1.9,-0.6,-0.4,0.1,0.1,-0.3,-1.6,-1.3,-1.2,0.8,0.7,-0.7,-1.2,-1.1,0.3,-0.1,-0.5
-jvs055,-1,0.6,-0.7,-1.8,0,-1.5,-1,-0.1,-0.3,-0.7,1.2,-1.3,-1.7,-1.6,-1.6,-1.3,-0.1,-1.1,-0.9,0,-0.6,-1.2,-0.7,-0.4,-0.3,3,-1.6,-1,-1.9,-1.3,-0.1,-1.1,-1.2,-1.3,-1.5,-0.3,-0.8,1,-1.5,-1.3,-1.4,-1.1,-0.7,0.3,-1.1,-1.8,-1.6,-0.8,0.4,-0.7,-0.5
-jvs056,-1.9,-2.2,-0.8,-1.4,-2.9,-1.9,-1.1,-0.7,-1.2,-2.2,-1,-0.8,-0.7,-1.3,-1,-1.2,-2.2,-1.5,-2.6,-1,-1.8,-1,-1.1,-2,-1.9,-1.6,3,0.5,-0.3,-1.6,-1.1,-1.9,-1.4,-1.3,-1.5,-2.2,-2,-1.2,-1,-0.2,-1.2,-1.6,-1.6,-1.6,-2.3,-0.9,-0.9,-1.6,-1.3,-2.1,-0.2
-jvs057,-0.5,-1.6,-0.2,0.7,-1.9,-2.2,-1.5,-0.4,-1.8,-0.9,-0.8,-0.8,-0.7,-1.8,-0.1,-0.8,-1.8,0.3,-2.4,-1.2,-1.1,-1,-0.8,-2,-0.5,-1,0.5,3,-0.5,-0.3,-0.4,-1.4,-1.4,-1.7,-0.8,-0.7,-1.9,-0.8,-0.6,-0.8,0,-1.4,-1.5,-1.3,-0.9,-1,-0.5,-1.7,-1.1,-0.9,-0.8
-jvs058,-1.2,-2,-0.5,-0.5,-1.5,-2.2,-1.5,-0.3,-1.6,-1.1,-1.1,-2,-0.4,-1.3,-0.9,-2,-1.6,0,-2.5,0.3,-0.6,-1.6,-0.4,-0.8,-0.6,-1.9,-0.3,-0.5,3,-0.8,-0.7,-1.7,-1.2,-0.7,-2.1,-0.9,-1.9,-0.9,-0.2,0.2,-0.1,-1.3,-1.4,-1.5,-0.5,-0.6,-1.8,-2.2,-0.1,-1.2,-1.5
-jvs059,-0.3,-1.8,-1.5,-1,-2.5,-1.8,-1,-0.6,-1.4,-0.9,-1.2,-1.4,-0.7,-1.8,-1,0,-1.6,-1.7,-1.2,-1.2,-1.3,-1.4,-0.8,-1.8,-0.3,-1.3,-1.6,-0.3,-0.8,3,-0.3,-1.1,-1.9,0.3,-0.5,-1.4,-1.2,-1.3,0,-0.1,-0.8,-1.6,-0.5,-1.1,-1.7,-1,0.9,-1.3,-0.8,-0.7,-0.1
-jvs060,0,-0.9,-0.4,-1,-1.5,-1.3,-1.3,-1,-0.9,-0.5,0.8,-0.8,-0.7,-1.1,-1.3,0.5,-1.4,-1.2,-1.6,-0.5,-0.6,-0.9,-0.3,-0.5,-0.6,-0.1,-1.1,-0.4,-0.7,-0.3,3,0.2,-0.6,0.2,-0.3,-0.5,-1.6,0.1,-0.4,-0.2,-0.9,-0.5,-0.1,0.1,-1.1,-0.6,-0.9,-1.6,-1.2,-0.5,0.9
-jvs061,0.3,-0.2,-0.7,-2.1,-2.3,-1.4,-0.5,-0.8,-1.4,-2.1,-0.8,-0.2,-0.2,-1,-1.2,-0.3,0.2,-1.1,0.2,-0.1,-0.6,-0.1,-1.1,-0.8,0.8,-1.1,-1.9,-1.4,-1.7,-1.1,0.2,3,-0.8,0.3,-0.8,-1.3,-0.8,-0.8,-1.4,-1.7,-2.2,0.3,-0.7,-0.6,-0.8,-0.6,-2,-1.1,-0.8,0,-0.3
-jvs062,-0.6,-0.6,-1.2,-1,-1,-1.4,-1,-0.7,-0.6,-0.2,-0.7,-0.8,-0.1,0,-0.8,-0.7,-1.3,0.2,0.9,-0.6,-0.3,-0.6,-0.8,-1,-0.3,-1.2,-1.4,-1.4,-1.2,-1.9,-0.6,-0.8,3,0.6,-1.8,-0.7,0.2,-1.5,-0.4,-0.5,-0.5,-0.5,-1,-0.6,-1,-1.3,-1,0.3,-0.6,0.1,-1.6
-jvs063,0.4,-0.7,-0.5,-1,-2.6,-2,0,-0.7,-0.6,-0.9,-0.2,-0.4,-0.7,0.1,-1.2,-0.5,0.4,-0.6,-0.8,0.2,-0.3,-0.1,-0.4,-0.1,-0.2,-1.3,-1.3,-1.7,-0.7,0.3,0.2,0.3,0.6,3,-0.5,-0.5,-1,0.1,-0.8,-0.3,-0.2,1.1,-0.1,-0.1,0.5,-0.5,-0.1,-0.8,-0.3,-0.2,0.2
-jvs064,0.1,-1.6,0.2,-2.1,-2.9,-1.6,-0.7,-0.3,-0.9,-0.7,-1.7,-0.3,-0.7,-1.1,-0.9,-0.2,0.1,-0.3,-0.6,-1.2,-1.4,-0.3,-0.5,-2.7,-1.9,-1.5,-1.5,-0.8,-2.1,-0.5,-0.3,-0.8,-1.8,-0.5,3,-0.7,-1,-1.4,0.1,-0.5,-0.3,-0.9,0.2,-0.2,-1.3,-0.6,-0.6,-1.4,-1.5,-0.8,-1.4
-jvs065,-1.3,-1.4,-1,-1.7,-2.3,-1.3,-0.5,-0.4,-0.9,-0.2,-1,0.1,-0.9,-0.6,-1.1,-1.3,-0.4,-1.3,-0.5,-0.5,0.3,-0.6,-1.1,0,-0.6,-0.3,-2.2,-0.7,-0.9,-1.4,-0.5,-1.3,-0.7,-0.5,-0.7,3,-0.3,-0.9,-0.6,-0.5,-0.7,-0.1,-1,0.5,-0.7,-1,-0.4,-1,-0.8,-0.5,-1.9
-jvs066,-1.3,-0.3,-1.4,-1.3,-1.4,-2.1,0.3,-0.3,-0.1,-0.3,-0.3,-0.3,-0.7,-0.9,-1.3,0.3,-0.7,0,-0.6,-0.5,-0.5,0.2,-1,0,-0.4,-0.8,-2,-1.9,-1.9,-1.2,-1.6,-0.8,0.2,-1,-1,-0.3,3,-0.5,-1.1,-0.3,-0.9,-0.4,-1.6,0.8,0,-1.4,-0.6,-0.6,-0.3,-0.1,-1.3
-jvs067,-0.6,-0.8,-0.8,-1.1,-0.2,-1.7,0,-0.7,-0.7,-0.3,-0.1,-1.2,-0.1,-1.6,-1.7,-0.7,-1.5,-1.8,-0.8,-0.4,-1.3,-2,-1,0,0.1,1,-1.2,-0.8,-0.9,-1.3,0.1,-0.8,-1.5,0.1,-1.4,-0.9,-0.5,3,-1.6,-0.9,-1.5,-1,-1.8,0,-0.2,-2,-1.5,0.4,0.9,-1.1,-0.6
-jvs069,-0.3,-1.6,-0.5,-0.5,-2.3,-0.9,-2.1,-0.4,-1.7,0,-0.6,-0.8,1.3,-0.9,-1.2,-0.4,-1.3,-0.5,-2.5,-0.4,-1.2,0,-0.8,-0.8,0.1,-1.5,-1,-0.6,-0.2,0,-0.4,-1.4,-0.4,-0.8,0.1,-0.6,-1.1,-1.6,3,-0.3,-0.3,-1,-0.5,-0.3,-1,0.3,-0.7,-2.3,-1,1.1,-0.3
-jvs072,0.3,-1.4,0.4,-0.2,-1.7,-2.5,-1.2,-1.3,-1.6,-0.3,0.1,-1.4,0.1,-1,-0.9,-0.5,-1.1,-0.7,-0.5,-0.8,-0.9,-1,-0.7,-1.1,-0.3,-1.3,-0.2,-0.8,0.2,-0.1,-0.2,-1.7,-0.5,-0.3,-0.5,-0.5,-0.3,-0.9,-0.3,3,-0.3,-1.5,-0.3,-0.3,-0.6,0.1,0.9,-1.4,0.5,-0.4,0.2
-jvs082,-1.5,-1.7,-0.5,-0.4,-1.6,-1.7,-1.3,-0.8,-2.4,-0.6,-1.1,-1,-1,0,0,-1,-1.5,-0.8,-2.4,0.3,-1.4,-1.1,-0.7,-0.7,-1.6,-1.4,-1.2,0,-0.1,-0.8,-0.9,-2.2,-0.5,-0.2,-0.3,-0.7,-0.9,-1.5,-0.3,-0.3,3,-0.9,-0.2,-0.1,-1.4,-2.1,-0.7,-2.1,-2.2,-0.4,-1
-jvs083,-1.2,-0.7,-0.1,-1.7,-0.4,-0.4,-0.7,-2,-1.3,-0.8,-1.1,-0.7,-0.7,0,-0.9,-1.2,-1.2,-1.1,-0.5,0.2,0,-0.7,-0.3,-0.4,-1.3,-1.1,-1.6,-1.4,-1.3,-1.6,-0.5,0.3,-0.5,1.1,-0.9,-0.1,-0.4,-1,-1,-1.5,-0.9,3,-1.4,-0.9,-0.4,-0.5,-0.8,-1.4,-0.6,-0.3,-1.2
-jvs084,-1.5,-1.7,-1,-1.8,-1.4,-2.7,-1.2,-1.1,-0.8,-0.9,-0.6,-0.8,-1.6,-1.5,-1.4,0.2,-0.8,-0.6,-1,-1,-1,-1.1,-0.7,-1.4,-1.2,-0.7,-1.6,-1.5,-1.4,-0.5,-0.1,-0.7,-1,-0.1,0.2,-1,-1.6,-1.8,-0.5,-0.3,-0.2,-1.4,3,-1.4,-0.8,-1.1,-0.3,-1.6,-0.3,-1.3,-1
-jvs085,-0.2,-1.6,-0.9,-2.1,-1.3,-1.9,-1.5,-1.1,-0.9,-0.1,-0.2,-0.3,-0.6,0,0,0.5,-1.2,-0.3,-0.7,0.3,-0.6,-0.6,-0.5,-0.5,0.8,0.3,-1.6,-1.3,-1.5,-1.1,0.1,-0.6,-0.6,-0.1,-0.2,0.5,0.8,0,-0.3,-0.3,-0.1,-0.9,-1.4,3,-0.3,-1.4,-1,-0.8,0.2,0.2,-1.3
-jvs090,-0.9,-0.2,-0.7,-1,-2.3,-0.6,-0.3,-1.8,-1.6,-0.7,-0.5,-0.2,-0.4,-0.8,-1.3,-0.5,-0.8,-1.1,-0.8,-0.7,-0.4,-0.9,-1,-0.8,0.7,-1.1,-2.3,-0.9,-0.5,-1.7,-1.1,-0.8,-1,0.5,-1.3,-0.7,0,-0.2,-1,-0.6,-1.4,-0.4,-0.8,-0.3,3,-1.4,-1.5,-1.2,-0.6,-0.3,-0.7
-jvs091,-0.7,-1.6,-1.2,-1.4,-1.7,-2.7,-1,-1.9,-1.6,-1.3,-0.6,-1.2,-0.8,-1.3,-0.8,-0.1,-2.1,-1.4,-1.3,-1.4,-1.5,-0.9,0.4,-1.8,-0.7,-1.8,-0.9,-1,-0.6,-1,-0.6,-0.6,-1.3,-0.5,-0.6,-1,-1.4,-2,0.3,0.1,-2.1,-0.5,-1.1,-1.4,-1.4,3,-0.7,-1.5,-0.6,-0.7,0
-jvs092,-0.5,-1.4,0.1,-1.5,-2.6,-2.2,-1.7,-0.1,-1.2,-0.3,-1.3,-0.7,-1,-0.8,-0.4,0,-0.7,-1.7,-1.3,-0.9,-0.9,-1,-1.3,-2.7,-1.2,-1.6,-0.9,-0.5,-1.8,0.9,-0.9,-2,-1,-0.1,-0.6,-0.4,-0.6,-1.5,-0.7,0.9,-0.7,-0.8,-0.3,-1,-1.5,-0.7,3,-2,-0.3,-0.9,-1
-jvs093,-1.6,0.3,-2.5,-1.6,-1,-0.1,-0.4,-1.3,-0.9,-2.3,-2.5,-0.3,-0.5,-2.1,-1.8,-1.5,-1.7,-0.8,-0.6,-1.8,-0.8,-2,-2,-0.2,-1.1,-0.8,-1.6,-1.7,-2.2,-1.3,-1.6,-1.1,0.3,-0.8,-1.4,-1,-0.6,0.4,-2.3,-1.4,-2.1,-1.4,-1.6,-0.8,-1.2,-1.5,-2,3,0.7,-1,-1.9
-jvs094,-0.7,-0.6,-0.9,-0.9,-1,-1.2,-1.4,-1.6,-1.3,-0.5,-0.4,-1.1,-0.3,0.2,-2,-1.1,-2.3,-0.8,-2.1,0,-0.4,-1.3,-0.6,0.9,0.3,0.4,-1.3,-1.1,-0.1,-0.8,-1.2,-0.8,-0.6,-0.3,-1.5,-0.8,-0.3,0.9,-1,0.5,-2.2,-0.6,-0.3,0.2,-0.6,-0.6,-0.3,0.7,3,-0.9,0
-jvs095,-0.2,-1.2,-1.2,-1,-1.9,-1.9,-0.7,0.4,-0.8,-0.2,-1.2,-0.4,-0.2,-0.4,0.2,0.8,-1.2,-1.3,-2.1,-0.7,-0.7,-1,0.6,-0.3,-0.1,-0.7,-2.1,-0.9,-1.2,-0.7,-0.5,0,0.1,-0.2,-0.8,-0.5,-0.1,-1.1,1.1,-0.4,-0.4,-0.3,-1.3,0.2,-0.3,-0.7,-0.9,-1,-0.9,3,-1.1
-jvs096,0.2,-1.3,-0.3,-1.3,-2.4,-1.5,-0.7,-1.3,-2.3,-1.1,1.3,-0.3,-0.8,-1.3,-1.9,0,-1.8,-0.9,-1,0,0,-1,-0.4,-0.2,-0.5,-0.5,-0.2,-0.8,-1.5,-0.1,0.9,-0.3,-1.6,0.2,-1.4,-1.9,-1.3,-0.6,-0.3,0.2,-1,-1.2,-1,-1.3,-0.7,0,-1,-1.9,0,-1.1,3
diff --git a/Speaker-Embeddings/data/speaker_similarity_male.csv b/Speaker-Embeddings/data/speaker_similarity_male.csv
deleted file mode 100755
index 40270d0..0000000
--- a/Speaker-Embeddings/data/speaker_similarity_male.csv
+++ /dev/null
@@ -1,49 +0,0 @@
-jvs001,3,0,-0.9,-1.9,-0.9,-0.7,0,0.2,-0.5,-1.2,-0.3,-1,-1.8,0,-1.2,-0.2,-0.1,-1.6,-1.9,-1.2,-0.7,-1.1,-1,-1.3,-1.4,-0.7,-1.4,-0.5,-0.9,-1.7,-1.4,-1.2,-1.1,-1,-0.7,-1.3,-0.7,-0.6,-1.2,-0.8,-0.6,-0.2,-0.5,-0.6,-1.3,-1.1,-1.6,-0.5,-0.5
-jvs003,0,3,-1.1,-1.3,-0.9,-1.3,-0.8,-0.7,-0.9,-0.9,-1.6,-1.1,-1.3,-1,-1.7,0.1,-0.2,-1.1,-2.2,-0.8,-1.2,0.3,-1.5,-0.1,-1.1,-1.3,-1.4,-0.6,-2.2,-1.6,-0.4,-1.2,0.2,-0.3,-0.5,-0.6,-0.8,-1.3,-1.4,-1,-0.8,0,-1.7,-1.3,-1.5,-0.7,-1.6,-0.9,-0.7
-jvs005,-0.9,-1.1,3,-1.9,-0.8,-2,-0.9,-0.3,-0.2,-1.1,-0.6,-0.5,-1.5,-0.7,-1.7,0.4,-1.7,-1.3,-0.5,-2.1,-1.6,-0.5,-1.6,-1.2,-0.9,-0.2,-1,-1.2,-1.4,-0.2,-0.2,-1.1,-1.1,-1.5,-0.9,-0.9,-0.5,-1.3,-0.7,0.2,-1,0.2,-1.1,-0.3,-1.4,-1.2,0,-0.2,-0.7
-jvs006,-1.9,-1.3,-1.9,3,-1.7,-1.5,-0.9,-1.7,-1,0,-1,-1.3,-0.6,-1.5,-1.8,-1.6,-1.1,-1.1,-1.6,-1.6,-1.4,-1.1,-1.2,0.2,-1.3,-1,-1.8,-1.8,-2,-1.1,-1,0.2,-2.1,-1,-1.8,-1.4,-2.2,-0.5,-1,-1.6,-1.2,-1.5,-1.9,-1.3,-1.7,-1.7,-2.2,-1.9,-1.2
-jvs009,-0.9,-0.9,-0.8,-1.7,3,-2.2,-0.6,-0.9,-1.5,0.3,-0.1,-0.8,-0.8,-0.6,-1.5,-0.7,0.1,-0.5,-1,-1.3,-2,-1.4,-0.7,-0.8,-0.5,-1.1,-0.5,-0.5,-1,-1.4,-1,0,-0.7,0.5,-1.1,-1.9,-1.2,-1.1,-1,-1.2,-1.3,-0.8,-0.7,-0.3,-1.3,-1.2,-1.4,-0.7,-0.3
-jvs011,-0.7,-1.3,-2,-1.5,-2.2,3,-1,-1.8,-2.1,-1.7,-1.8,-1.9,-2.1,-0.8,0.7,-1.4,-1.3,-1.9,-0.2,-2.2,-1.4,-0.6,-2,-1.7,-1,-0.8,-1.9,-1,-0.4,-0.4,-1.2,-2.3,0.6,-2.1,0,-1,-1.7,-1.3,-1.9,-2,-0.6,-1.7,-0.5,-0.9,-0.2,0.1,-1.2,-0.1,-1.9
-jvs012,0,-0.8,-0.9,-0.9,-0.6,-1,3,-0.3,-1.6,-1,-0.4,-0.8,-1.3,-0.5,-1,-0.5,-0.8,-0.4,-1.3,-1,-0.4,-0.4,-1.6,-1.4,-1.3,-0.3,-1.2,-0.5,-0.6,1.2,-0.4,0,-0.5,-0.3,-0.9,-1,-1.2,0.2,-1.1,-0.2,-0.2,0.5,-0.4,-0.5,-0.6,-1.1,-1.8,-0.5,-1
-jvs013,0.2,-0.7,-0.3,-1.7,-0.9,-1.8,-0.3,3,-0.5,-0.9,-0.5,0,-1.6,-0.9,-1.5,-0.3,-1.6,-2,-1.3,-1.6,-1,1,-1.3,-1.2,-1,-1.3,-1.1,-0.4,0,-1.9,-0.2,-1.2,-1,-0.6,0.1,-0.9,-1.1,-1.4,-0.9,-0.4,-0.9,0,-0.6,-0.4,-0.4,-0.8,-1.1,-1,-0.4
-jvs020,-0.5,-0.9,-0.2,-1,-1.5,-2.1,-1.6,-0.5,3,-0.6,-1,-1.1,-1.2,-1.4,-1.1,-0.3,-0.7,-1.1,-1.4,-1.6,-1.1,-1.2,-0.7,-1.3,-1.4,-1,-0.6,-1.4,-1.6,-1.4,-1,-1.6,-0.6,-0.8,-1.1,-0.9,-0.9,-1.2,-0.7,-1.1,-0.2,-0.8,-1.4,-1.4,-0.1,-1.5,-0.8,-1,-0.7
-jvs021,-1.2,-0.9,-1.1,0,0.3,-1.7,-1,-0.9,-0.6,3,-1.2,-1.3,-0.8,-0.3,-1.2,-0.9,-1,-0.9,-1.9,-0.3,-1.7,-1.4,-0.6,-1.1,-0.9,-1.3,-0.2,-1.2,-1.5,-1.3,-0.3,-0.9,-0.8,-0.9,-1.4,-1.2,-2.3,-0.4,-1.5,-0.9,-0.9,-0.8,-1,-0.8,-1.1,-1,-2.1,-1.1,-0.2
-jvs022,-0.3,-1.6,-0.6,-1,-0.1,-1.8,-0.4,-0.5,-1,-1.2,3,-0.4,-0.3,0.7,-1.6,-0.7,0.3,-0.6,-0.5,-0.2,-1.2,-0.1,-0.4,-0.5,-1.1,-1,0.3,-0.9,-0.6,0,-0.3,0.2,0.1,0.4,-1.3,-0.9,-0.8,-0.4,-1.1,0.1,-1.4,-0.6,-0.8,-0.2,-0.6,-0.2,-0.8,-1.3,-0.3
-jvs023,-1,-1.1,-0.5,-1.3,-0.8,-1.9,-0.8,0,-1.1,-1.3,-0.4,3,-1.3,-0.7,-0.7,-0.5,-1.2,-1.2,-0.8,-1.1,-1,-0.4,-0.5,-1.2,-1.2,-0.5,-1.4,-1.2,-1.1,-1,0.4,-1.7,-0.5,-0.7,-1.2,-0.3,0.4,-0.1,-0.3,-0.5,0.2,-0.7,-1.1,-0.4,-0.5,-0.2,-1.1,-0.7,-0.3
-jvs028,-1.8,-1.3,-1.5,-0.6,-0.8,-2.1,-1.3,-1.6,-1.2,-0.8,-0.3,-1.3,3,-1,-1.8,-1,-0.3,-0.3,-1.6,-1,-1,-1.2,-1.3,-0.8,-0.7,-1.2,-0.7,-1.4,-1.8,-1.3,-1.9,-0.7,-1,0.1,-0.9,-1.4,-1.6,-0.9,-1.9,-2.2,-1.3,-1.4,-1.2,-1.2,-1,-1.6,-1.7,-0.7,-1.6
-jvs031,0,-1,-0.7,-1.5,-0.6,-0.8,-0.5,-0.9,-1.4,-0.3,0.7,-0.7,-1,3,-0.5,-0.9,0.1,-0.2,-0.9,-0.1,-0.1,-0.5,-0.1,-0.4,-0.6,-1,-0.2,-1.2,-1.1,-0.5,-0.9,-1.2,0.4,-0.3,-0.9,-1.1,-1.1,-0.5,-1.1,-1,-1,-0.8,-1,0,-0.4,-1.5,-0.9,-1.1,-0.8
-jvs032,-1.2,-1.7,-1.7,-1.8,-1.5,0.7,-1,-1.5,-1.1,-1.2,-1.6,-0.7,-1.8,-0.5,3,-0.9,-1.8,-1.8,-1.1,-0.9,-2.1,-1.3,-1.5,-1.5,-1.4,-1.6,-1.6,-1.1,-0.1,-1.2,-1.5,-1.6,-1.3,-1.9,-1.1,-1,-0.6,-0.5,-1.5,-0.2,0.3,-1.1,-0.9,-1.2,-0.1,-0.8,-0.8,-0.8,-0.4
-jvs033,-0.2,0.1,0.4,-1.6,-0.7,-1.4,-0.5,-0.3,-0.3,-0.9,-0.7,-0.5,-1,-0.9,-0.9,3,-1.1,-0.7,-0.9,-1.8,-1,0.8,-0.1,-0.8,-1.5,-0.9,-0.4,-0.7,-1,0.2,0.7,-1,-0.8,-0.3,-0.4,0.2,-0.6,-1.1,0.1,-0.7,-0.7,-0.3,-1.6,-0.7,-1.4,-1.3,-1.5,0,-0.1
-jvs034,-0.1,-0.2,-1.7,-1.1,0.1,-1.3,-0.8,-1.6,-0.7,-1,0.3,-1.2,-0.3,0.1,-1.8,-1.1,3,0.4,-1.4,-1,-1.1,-0.4,-1.1,-1.5,-0.5,-0.4,0.2,-0.9,-1.3,-0.9,-0.1,-0.9,-1,-1,-0.4,-1.4,-1.4,-0.9,-1.2,-1.6,-1.7,-0.2,-0.6,-1.1,-0.7,-0.6,-1.6,-1.3,-1
-jvs037,-1.6,-1.1,-1.3,-1.1,-0.5,-1.9,-0.4,-2,-1.1,-0.9,-0.6,-1.2,-0.3,-0.2,-1.8,-0.7,0.4,3,-1.5,-1.7,-1.2,-1,-1.3,-0.4,-0.1,-0.1,-1.2,-1.4,-1.3,-1.2,-1,-1.1,-0.9,0.1,-0.6,-1.2,-1.6,-0.8,-1.1,-1.8,-1.1,-0.5,-1.1,-0.7,-1.4,-1.6,-1.4,-1.8,-0.2
-jvs041,-1.9,-2.2,-0.5,-1.6,-1,-0.2,-1.3,-1.3,-1.4,-1.9,-0.5,-0.8,-1.6,-0.9,-1.1,-0.9,-1.4,-1.5,3,0.1,-1.4,-2,-1.4,-1.4,-1.1,-1.4,-1.7,-1.7,-0.2,-0.7,-1,-1.6,-0.5,-1.3,-1.6,-1,-1.4,-0.6,-1.8,-1.3,-1.5,-1.2,-1.2,-0.6,-0.8,-1.6,-1.1,-0.8,-1.7
-jvs042,-1.2,-0.8,-2.1,-1.6,-1.3,-2.2,-1,-1.6,-1.6,-0.3,-0.2,-1.1,-1,-0.1,-0.9,-1.8,-1,-1.7,0.1,3,-1.2,-1.4,-1.3,-1.6,-1,-0.7,0.1,-1.1,0.1,-0.8,-1.7,0.2,0.4,-1.3,-0.8,-0.4,-1.3,-0.9,-1.2,-0.5,-1.5,-1.6,0.2,-0.4,-0.6,-0.7,-1.3,-1.3,-0.9
-jvs044,-0.7,-1.2,-1.6,-1.4,-2,-1.4,-0.4,-1,-1.1,-1.7,-1.2,-1,-1,-0.1,-2.1,-1,-1.1,-1.2,-1.4,-1.2,3,-2,-1,-0.5,-1.4,-0.5,-1.5,-1.8,-1.8,-0.3,-1.4,-1.4,-0.6,-0.8,-0.8,-0.6,-2.3,-0.5,-1.4,-1.6,-1.1,-1.3,-0.6,-0.3,-1,-1.1,-2.5,-1.2,-1.1
-jvs045,-1.1,0.3,-0.5,-1.1,-1.4,-0.6,-0.4,1,-1.2,-1.4,-0.1,-0.4,-1.2,-0.5,-1.3,0.8,-0.4,-1,-2,-1.4,-2,3,-1.2,-0.7,-0.7,-1.3,-0.9,0,-1.5,-0.4,0.5,-1,-0.6,-0.5,-0.4,-0.1,-1.4,-0.3,-1.1,-0.4,-0.6,1,-1,-1.1,-1.3,-0.5,-0.8,-1.5,-0.6
-jvs046,-1,-1.5,-1.6,-1.2,-0.7,-2,-1.6,-1.3,-0.7,-0.6,-0.4,-0.5,-1.3,-0.1,-1.5,-0.1,-1.1,-1.3,-1.4,-1.3,-1,-1.2,3,-0.9,-1,-0.6,-0.5,-0.5,-0.8,-0.1,-0.3,-0.3,-1.2,-0.8,-1.4,-0.6,-0.7,-0.2,0.1,-0.6,-1.4,-0.7,-0.3,-0.6,-0.5,-1.1,-1,-0.2,-0.8
-jvs047,-1.3,-0.1,-1.2,0.2,-0.8,-1.7,-1.4,-1.2,-1.3,-1.1,-0.5,-1.2,-0.8,-0.4,-1.5,-0.8,-1.5,-0.4,-1.4,-1.6,-0.5,-0.7,-0.9,3,-0.7,-1.3,-0.1,-1.1,-1.4,-0.5,-1.4,-0.6,-0.8,-0.4,-1.6,-2.1,-2.3,-1.8,-1,-0.8,-0.2,-0.9,-1.4,-1.6,-1.2,-1.4,-1.8,-1.1,-1.2
-jvs048,-1.4,-1.1,-0.9,-1.3,-0.5,-1,-1.3,-1,-1.4,-0.9,-1.1,-1.2,-0.7,-0.6,-1.4,-1.5,-0.5,-0.1,-1.1,-1,-1.4,-0.7,-1,-0.7,3,-1.1,-0.4,-1.7,-1.3,-0.3,-1.2,-0.9,-0.9,-0.6,-0.9,-1.6,-1.7,-0.9,-1.6,-1.2,-1.1,-1.6,-1.1,-0.5,-0.7,-0.8,-1.7,-1.2,-0.5
-jvs049,-0.7,-1.3,-0.2,-1,-1.1,-0.8,-0.3,-1.3,-1,-1.3,-1,-0.5,-1.2,-1,-1.6,-0.9,-0.4,-0.1,-1.4,-0.7,-0.5,-1.3,-0.6,-1.3,-1.1,3,0.4,-1.1,-1.1,-1.1,-0.6,-0.7,-0.7,-1.3,-0.4,-0.3,-1.3,0.1,-0.3,-0.9,-1.8,-1,-1.9,-0.8,-0.9,-1.2,-1.1,-1.1,-0.7
-jvs050,-1.4,-1.4,-1,-1.8,-0.5,-1.9,-1.2,-1.1,-0.6,-0.2,0.3,-1.4,-0.7,-0.2,-1.6,-0.4,0.2,-1.2,-1.7,0.1,-1.5,-0.9,-0.5,-0.1,-0.4,0.4,3,-0.9,-1.2,-1.4,-0.5,0,-1.2,-0.3,-1.2,-1.2,-0.2,-0.6,-0.3,-0.9,-0.3,-0.8,-0.9,-0.1,-1.4,-0.2,-1.2,-1.4,-0.9
-jvs052,-0.5,-0.6,-1.2,-1.8,-0.5,-1,-0.5,-0.4,-1.4,-1.2,-0.9,-1.2,-1.4,-1.2,-1.1,-0.7,-0.9,-1.4,-1.7,-1.1,-1.8,0,-0.5,-1.1,-1.7,-1.1,-0.9,3,0.1,-1.5,-0.6,-0.5,-0.1,-0.6,-0.2,-0.5,-1.1,-0.6,-1.3,-0.5,-0.5,-1.3,0.7,-1,-1,-0.9,-0.5,-0.7,-0.2
-jvs054,-0.9,-2.2,-1.4,-2,-1,-0.4,-0.6,0,-1.6,-1.5,-0.6,-1.1,-1.8,-1.1,-0.1,-1,-1.3,-1.3,-0.2,0.1,-1.8,-1.5,-0.8,-1.4,-1.3,-1.1,-1.2,0.1,3,-1.7,-0.6,-1.8,-0.8,-1.4,-0.9,0.1,-1.3,-1.9,-2.2,-0.9,-0.7,-1.5,-0.3,-1.4,-0.7,0.3,-0.9,-0.6,0.1
-jvs068,-1.7,-1.6,-0.2,-1.1,-1.4,-0.4,1.2,-1.9,-1.4,-1.3,0,-1,-1.3,-0.5,-1.2,0.2,-0.9,-1.2,-0.7,-0.8,-0.3,-0.4,-0.1,-0.5,-0.3,-1.1,-1.4,-1.5,-1.7,3,-0.1,-1,0.1,-0.5,-1.2,-1.3,-1.6,-0.2,0.4,0,-0.2,0.3,0,-0.3,-0.3,-0.8,-1,-0.8,-0.7
-jvs070,-1.4,-0.4,-0.2,-1,-1,-1.2,-0.4,-0.2,-1,-0.3,-0.3,0.4,-1.9,-0.9,-1.5,0.7,-0.1,-1,-1,-1.7,-1.4,0.5,-0.3,-1.4,-1.2,-0.6,-0.5,-0.6,-0.6,-0.1,3,-1.1,-0.6,-0.5,-0.5,-0.4,-1.5,-1.1,-1.1,0,0.1,0.5,-0.2,0.5,-1.4,-1.1,-0.5,-0.7,-0.9
-jvs071,-1.2,-1.2,-1.1,0.2,0,-2.3,0,-1.2,-1.6,-0.9,0.2,-1.7,-0.7,-1.2,-1.6,-1,-0.9,-1.1,-1.6,0.2,-1.4,-1,-0.3,-0.6,-0.9,-0.7,0,-0.5,-1.8,-1,-1.1,3,-0.8,0,-1.3,-1.3,-1.3,-0.5,-0.6,-1.1,-1.1,-0.6,-0.8,0.4,-1.2,-1.7,-2.1,-1.5,-1
-jvs073,-1.1,0.2,-1.1,-2.1,-0.7,0.6,-0.5,-1,-0.6,-0.8,0.1,-0.5,-1,0.4,-1.3,-0.8,-1,-0.9,-0.5,0.4,-0.6,-0.6,-1.2,-0.8,-0.9,-0.7,-1.2,-0.1,-0.8,0.1,-0.6,-0.8,3,-0.3,-1,-0.2,-1.4,0.4,-1.8,0,-1,-0.9,-0.5,0.7,-0.4,-0.9,-1.4,-0.8,-0.8
-jvs074,-1,-0.3,-1.5,-1,0.5,-2.1,-0.3,-0.6,-0.8,-0.9,0.4,-0.7,0.1,-0.3,-1.9,-0.3,-1,0.1,-1.3,-1.3,-0.8,-0.5,-0.8,-0.4,-0.6,-1.3,-0.3,-0.6,-1.4,-0.5,-0.5,0,-0.3,3,0.1,-1.9,-1,-1.3,-0.9,-0.8,-0.9,-0.5,-1.6,0.4,-1.3,-0.3,-1.9,-0.9,-0.9
-jvs075,-0.7,-0.5,-0.9,-1.8,-1.1,0,-0.9,0.1,-1.1,-1.4,-1.3,-1.2,-0.9,-0.9,-1.1,-0.4,-0.4,-0.6,-1.6,-0.8,-0.8,-0.4,-1.4,-1.6,-0.9,-0.4,-1.2,-0.2,-0.9,-1.2,-0.5,-1.3,-1,0.1,3,-0.8,0,-1.3,-1.2,-0.2,-0.3,-0.5,-0.5,-0.5,-1.5,0.3,-0.6,-0.4,0
-jvs076,-1.3,-0.6,-0.9,-1.4,-1.9,-1,-1,-0.9,-0.9,-1.2,-0.9,-0.3,-1.4,-1.1,-1,0.2,-1.4,-1.2,-1,-0.4,-0.6,-0.1,-0.6,-2.1,-1.6,-0.3,-1.2,-0.5,0.1,-1.3,-0.4,-1.3,-0.2,-1.9,-0.8,3,0,-1.2,-0.9,0.1,-0.4,-0.8,-0.3,-1,-0.3,-0.4,-0.5,-0.3,0.3
-jvs077,-0.7,-0.8,-0.5,-2.2,-1.2,-1.7,-1.2,-1.1,-0.9,-2.3,-0.8,0.4,-1.6,-1.1,-0.6,-0.6,-1.4,-1.6,-1.4,-1.3,-2.3,-1.4,-0.7,-2.3,-1.7,-1.3,-0.2,-1.1,-1.3,-1.6,-1.5,-1.3,-1.4,-1,0,0,3,-0.6,-0.1,0.1,0.2,-0.7,-0.5,-1.1,-0.5,-0.7,-0.2,-0.4,-0.8
-jvs078,-0.6,-1.3,-1.3,-0.5,-1.1,-1.3,0.2,-1.4,-1.2,-0.4,-0.4,-0.1,-0.9,-0.5,-0.5,-1.1,-0.9,-0.8,-0.6,-0.9,-0.5,-0.3,-0.2,-1.8,-0.9,0.1,-0.6,-0.6,-1.9,-0.2,-1.1,-0.5,0.4,-1.3,-1.3,-1.2,-0.6,3,-0.2,-0.2,-0.6,-0.5,-0.8,-1.1,-0.1,-0.1,-2.2,-0.4,-0.3
-jvs079,-1.2,-1.4,-0.7,-1,-1,-1.9,-1.1,-0.9,-0.7,-1.5,-1.1,-0.3,-1.9,-1.1,-1.5,0.1,-1.2,-1.1,-1.8,-1.2,-1.4,-1.1,0.1,-1,-1.6,-0.3,-0.3,-1.3,-2.2,0.4,-1.1,-0.6,-1.8,-0.9,-1.2,-0.9,-0.1,-0.2,3,-0.8,-0.4,-0.3,-0.4,-0.4,-0.1,-0.8,-1.5,-0.9,-0.7
-jvs080,-0.8,-1,0.2,-1.6,-1.2,-2,-0.2,-0.4,-1.1,-0.9,0.1,-0.5,-2.2,-1,-0.2,-0.7,-1.6,-1.8,-1.3,-0.5,-1.6,-0.4,-0.6,-0.8,-1.2,-0.9,-0.9,-0.5,-0.9,0,0,-1.1,0,-0.8,-0.2,0.1,0.1,-0.2,-0.8,3,-0.2,0.2,-0.5,-1.5,0.4,0.1,0.1,-0.5,-0.3
-jvs081,-0.6,-0.8,-1,-1.2,-1.3,-0.6,-0.2,-0.9,-0.2,-0.9,-1.4,0.2,-1.3,-1,0.3,-0.7,-1.7,-1.1,-1.5,-1.5,-1.1,-0.6,-1.4,-0.2,-1.1,-1.8,-0.3,-0.5,-0.7,-0.2,0.1,-1.1,-1,-0.9,-0.3,-0.4,0.2,-0.6,-0.4,-0.2,3,-0.1,-0.8,0,-0.4,-0.7,-1.6,1,0.4
-jvs086,-0.2,0,0.2,-1.5,-0.8,-1.7,0.5,0,-0.8,-0.8,-0.6,-0.7,-1.4,-0.8,-1.1,-0.3,-0.2,-0.5,-1.2,-1.6,-1.3,1,-0.7,-0.9,-1.6,-1,-0.8,-1.3,-1.5,0.3,0.5,-0.6,-0.9,-0.5,-0.5,-0.8,-0.7,-0.5,-0.3,0.2,-0.1,3,-0.9,-0.2,-0.3,-0.8,-2,-1.4,-0.1
-jvs087,-0.5,-1.7,-1.1,-1.9,-0.7,-0.5,-0.4,-0.6,-1.4,-1,-0.8,-1.1,-1.2,-1,-0.9,-1.6,-0.6,-1.1,-1.2,0.2,-0.6,-1,-0.3,-1.4,-1.1,-1.9,-0.9,0.7,-0.3,0,-0.2,-0.8,-0.5,-1.6,-0.5,-0.3,-0.5,-0.8,-0.4,-0.5,-0.8,-0.9,3,-0.5,-0.3,0.3,-0.6,0.2,-0.7
-jvs088,-0.6,-1.3,-0.3,-1.3,-0.3,-0.9,-0.5,-0.4,-1.4,-0.8,-0.2,-0.4,-1.2,0,-1.2,-0.7,-1.1,-0.7,-0.6,-0.4,-0.3,-1.1,-0.6,-1.6,-0.5,-0.8,-0.1,-1,-1.4,-0.3,0.5,0.4,0.7,0.4,-0.5,-1,-1.1,-1.1,-0.4,-1.5,0,-0.2,-0.5,3,-1.3,-0.8,-0.9,-1.9,-0.6
-jvs089,-1.3,-1.5,-1.4,-1.7,-1.3,-0.2,-0.6,-0.4,-0.1,-1.1,-0.6,-0.5,-1,-0.4,-0.1,-1.4,-0.7,-1.4,-0.8,-0.6,-1,-1.3,-0.5,-1.2,-0.7,-0.9,-1.4,-1,-0.7,-0.3,-1.4,-1.2,-0.4,-1.3,-1.5,-0.3,-0.5,-0.1,-0.1,0.4,-0.4,-0.3,-0.3,-1.3,3,-0.1,-1.2,-0.5,0.4
-jvs097,-1.1,-0.7,-1.2,-1.7,-1.2,0.1,-1.1,-0.8,-1.5,-1,-0.2,-0.2,-1.6,-1.5,-0.8,-1.3,-0.6,-1.6,-1.6,-0.7,-1.1,-0.5,-1.1,-1.4,-0.8,-1.2,-0.2,-0.9,0.3,-0.8,-1.1,-1.7,-0.9,-0.3,0.3,-0.4,-0.7,-0.1,-0.8,0.1,-0.7,-0.8,0.3,-0.8,-0.1,3,-0.4,-0.2,0.2
-jvs098,-1.6,-1.6,0,-2.2,-1.4,-1.2,-1.8,-1.1,-0.8,-2.1,-0.8,-1.1,-1.7,-0.9,-0.8,-1.5,-1.6,-1.4,-1.1,-1.3,-2.5,-0.8,-1,-1.8,-1.7,-1.1,-1.2,-0.5,-0.9,-1,-0.5,-2.1,-1.4,-1.9,-0.6,-0.5,-0.2,-2.2,-1.5,0.1,-1.6,-2,-0.6,-0.9,-1.2,-0.4,3,-0.4,-0.5
-jvs099,-0.5,-0.9,-0.2,-1.9,-0.7,-0.1,-0.5,-1,-1,-1.1,-1.3,-0.7,-0.7,-1.1,-0.8,0,-1.3,-1.8,-0.8,-1.3,-1.2,-1.5,-0.2,-1.1,-1.2,-1.1,-1.4,-0.7,-0.6,-0.8,-0.7,-1.5,-0.8,-0.9,-0.4,-0.3,-0.4,-0.4,-0.9,-0.5,1,-1.4,0.2,-1.9,-0.5,-0.2,-0.4,3,-1
-jvs100,-0.5,-0.7,-0.7,-1.2,-0.3,-1.9,-1,-0.4,-0.7,-0.2,-0.3,-0.3,-1.6,-0.8,-0.4,-0.1,-1,-0.2,-1.7,-0.9,-1.1,-0.6,-0.8,-1.2,-0.5,-0.7,-0.9,-0.2,0.1,-0.7,-0.9,-1,-0.8,-0.9,0,0.3,-0.8,-0.3,-0.7,-0.3,0.4,-0.1,-0.7,-0.6,0.4,0.2,-0.5,-1,3
diff --git a/Speaker-Embeddings/dataloader.py b/Speaker-Embeddings/dataloader.py
deleted file mode 100644
index a028832..0000000
--- a/Speaker-Embeddings/dataloader.py
+++ /dev/null
@@ -1,127 +0,0 @@
-import glob
-import numpy as np
-import os
-import random
-import librosa
-from random import shuffle
-from numpy.lib.stride_tricks import as_strided
-
-import torch
-from torch.utils.data import Dataset
-
-from hparam import hparam as hp
-from preprocess import get_para
-
-
-
-def get_max_flames():
-    sizes = []
-    for i, file in enumerate(glob.glob('./data/*/*/*.npy')):
-        arr = np.load(file)
-        size = arr.shape[0]
-        sizes.append(size)
-    max_size = max(sizes)
-    return max_size
-
-def standardization(x, axis=None, ddof=0):
-    x_mean = x.mean(axis=axis, keepdims=True)
-    x_std = x.std(axis=axis, keepdims=True, ddof=ddof)
-    return (x - x_mean) / x_std
-
-def mel_to_tensor(mel, device):
-    n_flames = mel.shape[0]
-    shape = (n_flames - hp.train.num_input_size + 1,
-             hp.train.num_input_size,
-             hp.train.num_mel_dim)
-
-    strides = mel.strides
-    stride_shape = (strides[0], strides[0], strides[1])
-
-    strided = as_strided(mel, shape=shape, strides=stride_shape)
-    strided = strided.reshape(shape[0], -1)
-
-    mel = standardization(strided, axis=1)
-    return torch.Tensor(mel).to(device)
-
-def get_dvector(model, utterance):
-    outputs = model(utterance)
-    return torch.mean(outputs, dim=0, keepdim=False)
-
-def audio_to_dvector(audio_path, model, device):
-    wav, source_sr = librosa.load(audio_path, sr=None)
-    # Resample the wav to 16kHz
-    wav = librosa.resample(wav, source_sr, hp.data.sr)
-    wav = wav.astype(np.float)
-
-    fo, mcep = get_para(wav, fs=hp.data.sr)
-
-    # remove silence using fo info
-    mask = fo.astype(np.bool)
-    mcep = mcep[mask, 1:]
-    mel = mel_to_tensor(mcep, device)
-    d_vector = get_dvector(model, mel)
-    return d_vector
-
-
-def utters_to_dvectors(utters, model, device):
-    d_vectors = []
-    for utter in utters:
-        # load utterance spectrogram of selected speaker
-        utterance = np.load(utter)
-        mel = mel_to_tensor(utterance, device)
-        d_vector = get_dvector(model, mel)
-        d_vectors.append(d_vector)
-    return d_vectors
-
-
-
-class JVSNonparaVal(Dataset):
-
-    def __init__(self, spekers_dict, device, model):
-        # data path
-        self.path = hp.data.nonpara_path
-        self.index2sp = {index: speaker for speaker, index in spekers_dict.items()}
-        self.input_size = hp.train.num_input_size
-        self.mel_dim = hp.train.num_mel_dim
-        self.shuffle = shuffle
-        self.device = device
-        self.model = model
-
-    def __len__(self):
-        return len(self.index2sp)
-
-    def __getitem__(self, idx):
-        selected_speaker = self.index2sp[idx]
-
-        search_path = os.path.join(self.path, selected_speaker, '*.npy')
-        # select random utterances
-        utters = random.sample(glob.glob(search_path), hp.test.M)
-        return utters_to_dvectors(utters, self.model, self.device)
-
-
-class JVSNonparaTrain(Dataset):
-    
-    def __init__(self, spekers_dict, device, model):
-        # data path
-        self.path = hp.data.nonpara_path
-        self.n_train_sp = (len(spekers_dict)//10)*9
-        self.index2sp = {index: speaker
-                         for speaker, index in spekers_dict.items()
-                         if index < self.n_train_sp}
-        self.input_size = hp.train.num_input_size
-        self.mel_dim = hp.train.num_mel_dim
-        self.shuffle = shuffle
-        self.device = device
-        self.model = model
-
-    def __len__(self):
-        return len(self.index2sp)
-
-    def __getitem__(self, idx):
-        selected_speaker = self.index2sp[idx]
-
-        d_vectors = []
-        search_path = os.path.join(self.path, selected_speaker, '*.npy')
-        # select random utterances
-        utters = random.sample(glob.glob(search_path), hp.train.M)
-        return utters_to_dvectors(utters, self.model, self.device)
\ No newline at end of file
diff --git a/Speaker-Embeddings/hparam.py b/Speaker-Embeddings/hparam.py
deleted file mode 100644
index 0c05fcd..0000000
--- a/Speaker-Embeddings/hparam.py
+++ /dev/null
@@ -1,58 +0,0 @@
-import yaml
-import os
-
-def load_hparam(filename):
-    stream = open(os.path.join(os.path.dirname(__file__), filename) , 'r')
-    docs = yaml.load_all(stream)
-    hparam_dict = dict()
-    for doc in docs:
-        for k, v in doc.items():
-            hparam_dict[k] = v
-    return hparam_dict
-
-
-def merge_dict(user, default):
-    if isinstance(user, dict) and isinstance(default, dict):
-        for k, v in default.items():
-            if k not in user:
-                user[k] = v
-            else:
-                user[k] = merge_dict(user[k], v)
-    return user
-
-
-class Dotdict(dict):
-    """
-    a dictionary that supports dot notation 
-    as well as dictionary access notation 
-    usage: d = DotDict() or d = DotDict({'val1':'first'})
-    set attributes: d.val2 = 'second' or d['val2'] = 'second'
-    get attributes: d.val2 or d['val2']
-    """
-    __getattr__ = dict.__getitem__
-    __setattr__ = dict.__setitem__
-    __delattr__ = dict.__delitem__
-
-    def __init__(self, dct=None):
-        dct = dict() if not dct else dct
-        for key, value in dct.items():
-            if hasattr(value, 'keys'):
-                value = Dotdict(value)
-            self[key] = value
-
-
-class Hparam(Dotdict):
-
-    def __init__(self, file='config/config.yaml'):
-        super(Dotdict, self).__init__()
-        hp_dict = load_hparam(file)
-        hp_dotdict = Dotdict(hp_dict)
-        for k, v in hp_dotdict.items():
-            setattr(self, k, v)
-            
-    __getattr__ = Dotdict.__getitem__
-    __setattr__ = Dotdict.__setitem__
-    __delattr__ = Dotdict.__delitem__
-
-        
-hparam = Hparam()
diff --git a/Speaker-Embeddings/model/__init__.py b/Speaker-Embeddings/model/__init__.py
deleted file mode 100644
index 0ac7775..0000000
--- a/Speaker-Embeddings/model/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from .ffnet import FFNet, SimMatrixLoss
\ No newline at end of file
diff --git a/Speaker-Embeddings/model/ckpt/final_epoch_700.model b/Speaker-Embeddings/model/ckpt/final_epoch_700.model
deleted file mode 100644
index c2a0bad..0000000
Binary files a/Speaker-Embeddings/model/ckpt/final_epoch_700.model and /dev/null differ
diff --git a/Speaker-Embeddings/model/ffnet.py b/Speaker-Embeddings/model/ffnet.py
deleted file mode 100644
index 1ccc058..0000000
--- a/Speaker-Embeddings/model/ffnet.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import numpy as np
-import pandas as pd
-from sklearn.preprocessing import MinMaxScaler
-
-import torch
-import torch.nn as nn
-
-
-
-class FFNet(nn.Module):
-
-    def __init__(self, input_size=5*39, hidden_size=256, d_vector_size=8):
-        super().__init__()
-
-        self.fc1 = nn.Linear(input_size, hidden_size)
-        self.fc2 = nn.Linear(hidden_size, hidden_size)
-        self.fc3 = nn.Linear(hidden_size, hidden_size)
-        self.bottle_neck = nn.Linear(hidden_size, d_vector_size)
-        self.layers = nn.ModuleList(
-            [self.fc1, self.fc2, self.fc3, self.bottle_neck])
-
-        for name, param in self.layers.named_parameters():
-            if 'bias' in name:
-                nn.init.constant_(param, 0.0)
-            elif 'weight' in name:
-                nn.init.xavier_normal_(param)
-
-
-    def forward(self, x):
-        for layer in self.layers:
-            x = layer(x)
-            x = torch.tanh(x)
-        out = x
-        return out
-
-
-class SimMatrixLoss(nn.Module):
-    def __init__(self, device, sim_csv_path, gamma=1.0):
-        super().__init__()
-        self.device = device
-        self.max_similarity = 1.0
-        self.scaler = MinMaxScaler()
-        self.gamma = gamma
-
-        self._get_normalized_simmatrix(sim_csv_path)
-
-    def _get_normalized_simmatrix(self, path):
-        simmat = pd.read_csv(path, header=None, index_col=0)
-        self.sp2idx = {speaker: index
-                       for index, speaker in enumerate(simmat.index)}
-
-        W = np.array(simmat > 0).astype(np.float)
-        self.W = torch.Tensor(W).to(self.device)
-        simmat = self.scaler.fit_transform(simmat)
-        self.simmat = torch.Tensor(simmat).to(self.device)
-
-    def _gaussian_kernel(self, di, dj):
-        diff = di - dj
-        norm = torch.norm(diff, p=2, dim=1, keepdim=True)
-        return torch.exp(-self.gamma * norm)
-
-    def _loss_simmat_re(self, Kd, S, W):
-        Ns = W.size(0)
-        batch_size = Kd.shape[-1]
-
-        S = S.unsqueeze(2).repeat(1, 1, batch_size)
-        W = W.unsqueeze(2).repeat(1, 1, batch_size)
-        Is = torch.eye(Ns).to(self.device).unsqueeze(2).repeat(1, 1, batch_size)
-
-        denom = torch.norm(W - Is, p="fro")
-
-        S_tilde = S - self.max_similarity * Is
-        Kd_tilde = Kd - torch.mul(Kd, Is)
-        diff = Kd_tilde - S_tilde
-        diff_normed = torch.mul(W, diff)
-        numer = torch.norm(diff_normed, p="fro")
-
-        loss = 2 * (numer / denom)
-        return loss
-
-
-    def forward(self, d_vectors):
-        Ns = d_vectors[0].shape[0]
-
-        utter = torch.stack(d_vectors).permute(1, 2, 0)
-        ks = [self._gaussian_kernel(utter, utter[i]) for i in range(Ns)]
-        gram_matrix = torch.cat(ks, dim=1)
-
-        part_sim, part_W = self.simmat[:Ns, :Ns], self.W[:Ns, :Ns]
-
-        loss = self._loss_simmat_re(gram_matrix, part_sim, part_W)
-        return loss
\ No newline at end of file
diff --git a/Speaker-Embeddings/output/simmat_VOICEACTRESS100_001.csv b/Speaker-Embeddings/output/simmat_VOICEACTRESS100_001.csv
deleted file mode 100644
index 793fd8d..0000000
--- a/Speaker-Embeddings/output/simmat_VOICEACTRESS100_001.csv
+++ /dev/null
@@ -1,52 +0,0 @@
-jvs002,1.0,0.4607063,0.48454052,0.58717734,0.44627407,0.3686748,0.43024302,0.5318761,0.42293543,0.51330847,0.43616375,0.46930617,0.51368904,0.5330402,0.5610221,0.40312314,0.4121995,0.6330706,0.40093312,0.40064633,0.45005983,0.51402855,0.31829476,0.3536142,0.36671254,0.4719735,0.46138057,0.38533875,0.6448472,0.50828254,0.35170403,0.5055648,0.40001088,0.42413616,0.434583,0.35263893,0.38992307,0.4730869,0.5055683,0.41780445,0.40977538,0.37062833,0.45870715,0.36674196,0.38923573,0.5937911,0.43374446,0.41313696,0.30763423,0.40986836,0.37400877,0.46006167
-jvs004,0.4607063,1.0,0.560567,0.48916668,0.56048703,0.45844042,0.45358405,0.51061726,0.4874371,0.5221612,0.45313233,0.4653462,0.58265007,0.60024816,0.5510991,0.5073004,0.39787492,0.48182368,0.49374634,0.5644742,0.43638438,0.4561046,0.47462976,0.44644687,0.5374387,0.47154903,0.56733066,0.42197418,0.5521387,0.70228535,0.39507753,0.41327146,0.411887,0.57706344,0.6241211,0.46159226,0.47777793,0.5156665,0.5149473,0.4520729,0.66072404,0.4820598,0.5783196,0.7128247,0.5704388,0.58015513,0.54633373,0.580551,0.36113253,0.5473224,0.5174066,0.6057587
-jvs007,0.48454052,0.560567,1.0,0.63074625,0.616111,0.4846424,0.44342485,0.6168016,0.5197449,0.63492376,0.77734524,0.57080203,0.6874447,0.5345977,0.49803463,0.47808072,0.35574743,0.47161072,0.42626,0.5894808,0.63219017,0.41883484,0.4493987,0.606555,0.4891904,0.5886189,0.6908855,0.46785396,0.61057764,0.64976215,0.53337026,0.41031662,0.35082707,0.4733587,0.46263626,0.3955815,0.60508347,0.677058,0.60017717,0.56646585,0.5141954,0.4094473,0.5691284,0.5098971,0.47830066,0.62379676,0.78269815,0.48527485,0.4837551,0.44140765,0.57797927,0.6358979
-jvs008,0.58717734,0.48916668,0.63074625,1.0,0.5345869,0.46260157,0.5175372,0.735166,0.4964448,0.6970613,0.57794297,0.51196754,0.6375503,0.59944284,0.59929246,0.55511,0.45242575,0.64057595,0.44893178,0.50043267,0.608085,0.5500227,0.43539402,0.4952411,0.43738163,0.5955091,0.564288,0.542385,0.7318256,0.5849072,0.55763644,0.47264278,0.43211946,0.49715483,0.47616988,0.4006215,0.56239295,0.5941453,0.5730849,0.48369807,0.4758965,0.44630417,0.5848115,0.42295456,0.48335811,0.55036384,0.5692747,0.49977562,0.5042609,0.47634295,0.48900142,0.60909736
-jvs010,0.44627407,0.56048703,0.616111,0.5345869,1.0,0.5222666,0.5645843,0.5226198,0.70459235,0.71570116,0.52173513,0.50967103,0.66170204,0.66956955,0.5040133,0.43241104,0.45492345,0.44753423,0.43883342,0.5000964,0.42421764,0.46232277,0.4294803,0.47423187,0.4197144,0.5318709,0.5043097,0.36428064,0.56458515,0.57743466,0.3859934,0.39955658,0.41177377,0.4058117,0.44435894,0.36273277,0.5347121,0.5647744,0.5165252,0.71953636,0.46265224,0.39954183,0.5634752,0.4680131,0.5557681,0.49535924,0.6322663,0.6038404,0.3946383,0.4747711,0.45138618,0.53700763
-jvs014,0.3686748,0.45844042,0.4846424,0.46260157,0.5222666,1.0,0.45420733,0.39620885,0.56267375,0.5193048,0.48032185,0.56257606,0.561941,0.5251686,0.3985333,0.42340252,0.45491228,0.4587287,0.5170081,0.6167735,0.46106285,0.41655496,0.49830455,0.5827478,0.5109405,0.6148966,0.45614058,0.37358868,0.47117332,0.46244708,0.41842747,0.5169988,0.34554395,0.41822818,0.4074781,0.47965035,0.66872716,0.6095532,0.599681,0.44801638,0.5201656,0.47584495,0.5114403,0.45218247,0.61250174,0.42881036,0.5325173,0.51403916,0.41145417,0.43066734,0.5758334,0.54990536
-jvs015,0.43024302,0.45358405,0.44342485,0.5175372,0.5645843,0.45420733,1.0,0.5372447,0.534706,0.62824124,0.386044,0.38429868,0.57344496,0.70084506,0.5573289,0.4370998,0.53803533,0.5213815,0.4052184,0.39196342,0.35342756,0.48256934,0.36900783,0.38278714,0.32989278,0.40914416,0.38154227,0.33084613,0.5663007,0.48962906,0.35707304,0.3688106,0.4247494,0.38971823,0.47897547,0.31888577,0.42537645,0.43807122,0.42663547,0.4480199,0.42728227,0.42833978,0.61361355,0.3896251,0.53465545,0.39266184,0.43132606,0.59605086,0.34383604,0.5358553,0.37820774,0.44624665
-jvs016,0.5318761,0.51061726,0.6168016,0.735166,0.5226198,0.39620885,0.5372447,1.0,0.44172907,0.64156985,0.5287772,0.42032367,0.62673587,0.58013755,0.64784837,0.55936825,0.39850187,0.5702921,0.3935215,0.45516837,0.52375734,0.48287764,0.41094762,0.4557774,0.39928678,0.46770364,0.55802387,0.4923631,0.6855844,0.63987124,0.5263498,0.3707524,0.40989795,0.5029082,0.5343903,0.34918395,0.4800817,0.50612396,0.4936648,0.4582761,0.4804066,0.43307796,0.6383134,0.44267792,0.45928702,0.53010964,0.54111445,0.50722545,0.45479885,0.5161939,0.4584564,0.57088345
-jvs017,0.42293543,0.4874371,0.5197449,0.4964448,0.70459235,0.56267375,0.534706,0.44172907,1.0,0.6714941,0.46772838,0.57939464,0.5465476,0.62394017,0.45237973,0.3959853,0.5166648,0.437341,0.5136579,0.48211768,0.40378615,0.49010482,0.4117033,0.45358285,0.39881927,0.5592017,0.41432002,0.35053456,0.5081377,0.46036446,0.35195145,0.4497699,0.42054567,0.37493312,0.39217633,0.39790794,0.5273428,0.58936113,0.46986923,0.5981908,0.41879305,0.4017118,0.48422027,0.43169853,0.5651839,0.42130813,0.5144701,0.55655843,0.3882776,0.43199185,0.42850417,0.47732845
-jvs018,0.51330847,0.5221612,0.63492376,0.6970613,0.71570116,0.5193048,0.62824124,0.64156985,0.6714941,1.0,0.55174273,0.5356882,0.67077875,0.7142393,0.59420943,0.51026547,0.520791,0.5502953,0.48570672,0.5084887,0.4978965,0.5612694,0.4515593,0.50189495,0.42315382,0.58780706,0.51292765,0.4443447,0.6563255,0.5779625,0.45915043,0.44061932,0.46848992,0.45308226,0.47455117,0.39375398,0.5768333,0.6208561,0.52996707,0.6153208,0.4688697,0.45188707,0.61852324,0.45012814,0.56950253,0.49367574,0.5918875,0.6101458,0.47095886,0.5162096,0.47398618,0.57909554
-jvs019,0.43616375,0.45313233,0.77734524,0.57794297,0.52173513,0.48032185,0.386044,0.5287772,0.46772838,0.55174273,1.0,0.5821171,0.60950077,0.4493457,0.41157925,0.41414145,0.31417474,0.42801332,0.38391846,0.5558668,0.68557465,0.3622837,0.4064852,0.6446155,0.45222896,0.5884969,0.61774635,0.4369741,0.54135585,0.5292309,0.55057853,0.40530664,0.2942688,0.40786725,0.38355616,0.3679209,0.6071101,0.6691931,0.595667,0.50207,0.45034704,0.36395857,0.48867488,0.430389,0.41528112,0.56320316,0.7207073,0.403589,0.48794624,0.3675513,0.56997377,0.5610101
-jvs024,0.46930617,0.4653462,0.57080203,0.51196754,0.50967103,0.56257606,0.38429868,0.42032367,0.57939464,0.5356882,0.5821171,1.0,0.52231514,0.48260537,0.4043576,0.3815689,0.391802,0.45707378,0.5272794,0.57315,0.5542685,0.4304843,0.4019972,0.5395209,0.4736632,0.68677723,0.47878486,0.3998952,0.50941765,0.4528036,0.40421128,0.5751063,0.33728257,0.40333053,0.37144047,0.4748659,0.57584286,0.75798947,0.57050806,0.4738549,0.44627178,0.39605752,0.43458036,0.44090953,0.46818468,0.51159066,0.53984153,0.42138252,0.4042843,0.3670197,0.5260558,0.5108592
-jvs025,0.51368904,0.58265007,0.6874447,0.6375503,0.66170204,0.561941,0.57344496,0.62673587,0.5465476,0.67077875,0.60950077,0.52231514,1.0,0.6671466,0.54656506,0.48488083,0.42232972,0.5628662,0.42903137,0.56169707,0.52891344,0.44747198,0.44086394,0.55053437,0.4657119,0.56040204,0.608949,0.41224393,0.72308093,0.6946316,0.48666653,0.45519394,0.3689639,0.47358063,0.5182079,0.38484582,0.5855028,0.60733914,0.6828462,0.5413201,0.5657794,0.44456744,0.68984526,0.4940592,0.5447263,0.6261553,0.70445067,0.5594211,0.41738427,0.50284225,0.5504863,0.62868094
-jvs026,0.5330402,0.60024816,0.5345977,0.59944284,0.66956955,0.5251686,0.70084506,0.58013755,0.62394017,0.7142393,0.4493457,0.48260537,0.6671466,1.0,0.6480131,0.5099868,0.5876867,0.6104684,0.50661814,0.49410883,0.42335877,0.59129584,0.4430739,0.43436414,0.43185595,0.5205846,0.48179528,0.40106103,0.67179996,0.61196744,0.39378312,0.47131792,0.50088066,0.4850396,0.5550624,0.41017365,0.5055448,0.53642356,0.5337572,0.5274153,0.5282158,0.49077907,0.65668356,0.4858045,0.63359505,0.508122,0.5236852,0.69330096,0.37863564,0.59040064,0.45199,0.56460774
-jvs027,0.5610221,0.5510991,0.49803463,0.59929246,0.5040133,0.3985333,0.5573289,0.64784837,0.45237973,0.59420943,0.41157925,0.4043576,0.54656506,0.6480131,1.0,0.60265744,0.5086949,0.6456648,0.479449,0.4601529,0.43316585,0.62604195,0.44416782,0.4005743,0.4261323,0.45122132,0.49977306,0.45990276,0.594454,0.6300368,0.40163124,0.3980623,0.5614425,0.5827714,0.6588543,0.40712515,0.43867785,0.4758789,0.4590131,0.4461741,0.5191709,0.5419848,0.65404344,0.47474095,0.5410362,0.48557946,0.44777423,0.62406075,0.37171054,0.68786836,0.43184367,0.56570673
-jvs029,0.40312314,0.5073004,0.47808072,0.55511,0.43241104,0.42340252,0.4370998,0.55936825,0.3959853,0.51026547,0.41414145,0.3815689,0.48488083,0.5099868,0.60265744,1.0,0.44496885,0.5299488,0.49802348,0.5348575,0.48787427,0.54302824,0.636767,0.46763545,0.5396758,0.47950622,0.5383769,0.6498216,0.48151085,0.5735779,0.53141725,0.3725041,0.5110304,0.71539664,0.6018276,0.49347037,0.52602863,0.47465783,0.4535916,0.3868832,0.5728479,0.63245636,0.5952801,0.5083156,0.56920165,0.41985673,0.45723522,0.5776441,0.5097078,0.627041,0.5178322,0.6716561
-jvs030,0.4121995,0.39787492,0.35574743,0.45242575,0.45492345,0.45491228,0.53803533,0.39850187,0.5166648,0.520791,0.31417474,0.391802,0.42232972,0.5876867,0.5086949,0.44496885,1.0,0.5187037,0.52616686,0.39072007,0.32715932,0.67546964,0.40972233,0.3373121,0.3608556,0.45091,0.33679867,0.35516575,0.44098863,0.39643177,0.30591968,0.44674134,0.606377,0.40012035,0.41471267,0.40688106,0.41703713,0.41954473,0.39005005,0.40661216,0.38955426,0.48008785,0.45891008,0.35152364,0.5634189,0.3330408,0.35077265,0.5746961,0.33010462,0.5014437,0.346393,0.4291511
-jvs035,0.6330706,0.48182368,0.47161072,0.64057595,0.44753423,0.4587287,0.5213815,0.5702921,0.437341,0.5502953,0.42801332,0.45707378,0.5628662,0.6104684,0.6456648,0.5299488,0.5187037,1.0,0.48465598,0.47235867,0.48391652,0.59619576,0.41049767,0.41670385,0.43295825,0.5126883,0.4787688,0.4557033,0.66236186,0.54758096,0.42660597,0.5460109,0.45815846,0.5326689,0.54253393,0.43369785,0.46871522,0.50643235,0.5565732,0.38989672,0.51478636,0.5187031,0.58602744,0.41584185,0.50565886,0.5200973,0.4413131,0.51043206,0.36687896,0.5337609,0.45456988,0.5524034
-jvs036,0.40093312,0.49374634,0.42626,0.44893178,0.43883342,0.5170081,0.4052184,0.3935215,0.5136579,0.48570672,0.38391846,0.5272794,0.42903137,0.50661814,0.479449,0.49802348,0.52616686,0.48465598,1.0,0.5693577,0.42997143,0.5670451,0.5336273,0.45292467,0.5351275,0.54216653,0.415148,0.45125845,0.42829427,0.4425485,0.36507282,0.49810365,0.4939715,0.5341726,0.4755859,0.7023848,0.5119412,0.5609456,0.4380429,0.38760367,0.5159125,0.6112525,0.4684637,0.5189972,0.63589793,0.3883097,0.40215224,0.54329973,0.39354292,0.5079459,0.50086063,0.5300679
-jvs038,0.40064633,0.5644742,0.5894808,0.50043267,0.5000964,0.6167735,0.39196342,0.45516837,0.48211768,0.5084887,0.5558668,0.57315,0.56169707,0.49410883,0.4601529,0.5348575,0.39072007,0.47235867,0.5693577,1.0,0.5916773,0.43447044,0.6337414,0.6983471,0.75271887,0.6377995,0.6345797,0.49788556,0.4803171,0.5806042,0.502963,0.46926314,0.37315232,0.5846971,0.50613075,0.60348,0.71239084,0.68862665,0.61744326,0.45136878,0.67325383,0.5645579,0.5574868,0.6150545,0.6092435,0.5145247,0.60114294,0.5291737,0.47229403,0.49345678,0.8085976,0.7401001
-jvs039,0.45005983,0.43638438,0.63219017,0.608085,0.42421764,0.46106285,0.35342756,0.52375734,0.40378615,0.4978965,0.68557465,0.5542685,0.52891344,0.42335877,0.43316585,0.48787427,0.32715932,0.48391652,0.42997143,0.5916773,1.0,0.40116474,0.45523047,0.63229007,0.5185637,0.61720806,0.6253294,0.5724516,0.52098745,0.5108403,0.64931273,0.4481711,0.3200521,0.49066693,0.41034168,0.4469831,0.6180745,0.64983875,0.58874255,0.40521288,0.48444796,0.42444962,0.47967035,0.43570313,0.42093927,0.53524834,0.5769179,0.39351863,0.54254717,0.38629237,0.62167025,0.6133621
-jvs040,0.51402855,0.4561046,0.41883484,0.5500227,0.46232277,0.41655496,0.48256934,0.48287764,0.49010482,0.5612694,0.3622837,0.4304843,0.44747198,0.59129584,0.62604195,0.54302824,0.67546964,0.59619576,0.5670451,0.43447044,0.40116474,1.0,0.44843706,0.36379522,0.4183329,0.50597125,0.4120459,0.46804428,0.50173885,0.46609232,0.35964027,0.47179002,0.72429955,0.49804705,0.47251832,0.46152282,0.44469672,0.46886548,0.4247019,0.43110687,0.42969194,0.5129725,0.4847577,0.3973625,0.53843004,0.4007134,0.3911699,0.56679344,0.38045937,0.53573865,0.38395068,0.50552917
-jvs043,0.31829476,0.47462976,0.4493987,0.43539402,0.4294803,0.49830455,0.36900783,0.41094762,0.4117033,0.4515593,0.4064852,0.4019972,0.44086394,0.4430739,0.44416782,0.636767,0.40972233,0.41049767,0.5336273,0.6337414,0.45523047,0.44843706,1.0,0.5343272,0.6600616,0.50830084,0.51072586,0.5349604,0.3857487,0.49272445,0.47275108,0.3632309,0.43621868,0.59222895,0.4863267,0.5718636,0.6026654,0.49419048,0.44769162,0.39794508,0.5677248,0.61784095,0.50717956,0.5302414,0.62074494,0.3716781,0.4655659,0.5572898,0.50602615,0.52893955,0.5819298,0.65071297
-jvs051,0.3536142,0.44644687,0.606555,0.4952411,0.47423187,0.5827478,0.38278714,0.4557774,0.45358285,0.50189495,0.6446155,0.5395209,0.55053437,0.43436414,0.4005743,0.46763545,0.3373121,0.41670385,0.45292467,0.6983471,0.63229007,0.36379522,0.5343272,1.0,0.54942435,0.5850512,0.57466686,0.45709112,0.4528696,0.50314015,0.5716222,0.3958082,0.30711612,0.46327415,0.4201418,0.4565159,0.73243475,0.6766569,0.5643076,0.438661,0.52972305,0.4671661,0.5278115,0.4899999,0.50617194,0.45261782,0.611476,0.45173055,0.53157467,0.42026368,0.76061493,0.6171123
-jvs053,0.36671254,0.5374387,0.4891904,0.43738163,0.4197144,0.5109405,0.32989278,0.39928678,0.39881927,0.42315382,0.45222896,0.4736632,0.4657119,0.43185595,0.4261323,0.5396758,0.3608556,0.43295825,0.5351275,0.75271887,0.5185637,0.4183329,0.6600616,0.54942435,1.0,0.55786574,0.5989794,0.5161148,0.4158471,0.53315955,0.45786414,0.43939808,0.37480846,0.6202042,0.4864325,0.6487411,0.592034,0.5431906,0.5423077,0.3882587,0.64877564,0.54955167,0.47693416,0.58713645,0.5458444,0.47279778,0.50864476,0.47964278,0.43048838,0.46339458,0.6650221,0.68676335
-jvs055,0.4719735,0.47154903,0.5886189,0.5955091,0.5318709,0.6148966,0.40914416,0.46770364,0.5592017,0.58780706,0.5884969,0.68677723,0.56040204,0.5205846,0.45122132,0.47950622,0.45091,0.5126883,0.54216653,0.6377995,0.61720806,0.50597125,0.50830084,0.5850512,0.55786574,1.0,0.5575245,0.5006505,0.5328404,0.5017655,0.48944226,0.58554286,0.40268746,0.46528977,0.401654,0.516673,0.7270997,0.73685575,0.6471635,0.517032,0.48484635,0.45505086,0.48373672,0.43874758,0.52878165,0.5112167,0.59759635,0.48179665,0.49991256,0.4157314,0.56767565,0.63120115
-jvs056,0.46138057,0.56733066,0.6908855,0.564288,0.5043097,0.45614058,0.38154227,0.55802387,0.41432002,0.51292765,0.61774635,0.47878486,0.608949,0.48179528,0.49977306,0.5383769,0.33679867,0.4787688,0.415148,0.6345797,0.6253294,0.4120459,0.51072586,0.57466686,0.5989794,0.5575245,1.0,0.51657367,0.5388397,0.7097233,0.5431362,0.4038695,0.3571774,0.5639185,0.50628376,0.43159276,0.5830487,0.5749268,0.63005364,0.4834987,0.5884991,0.4493512,0.5602257,0.5285924,0.4729557,0.6442971,0.69043213,0.47687873,0.45386034,0.46513227,0.61539906,0.7353094
-jvs057,0.38533875,0.42197418,0.46785396,0.542385,0.36428064,0.37358868,0.33084613,0.4923631,0.35053456,0.4443447,0.4369741,0.3998952,0.41224393,0.40106103,0.45990276,0.6498216,0.35516575,0.4557033,0.45125845,0.49788556,0.5724516,0.46804428,0.5349604,0.45709112,0.5161148,0.5006505,0.51657367,1.0,0.43480027,0.46465904,0.59685,0.37626868,0.4114959,0.5831123,0.4337253,0.48722994,0.512811,0.47423273,0.42833957,0.34344533,0.459997,0.4744955,0.43924782,0.42895836,0.4295212,0.40506035,0.43471602,0.41226637,0.5941264,0.4243095,0.4916092,0.5854786
-jvs058,0.6448472,0.5521387,0.61057764,0.7318256,0.56458515,0.47117332,0.5663007,0.6855844,0.5081377,0.6563255,0.54135585,0.50941765,0.72308093,0.67179996,0.594454,0.48151085,0.44098863,0.66236186,0.42829427,0.4803171,0.52098745,0.50173885,0.3857487,0.4528696,0.4158471,0.5328404,0.5388397,0.43480027,1.0,0.6261822,0.466206,0.49598676,0.39324814,0.47242573,0.506378,0.37627658,0.50005776,0.5571766,0.6082127,0.46844575,0.5054995,0.42151457,0.6058019,0.4455726,0.48237205,0.6363261,0.568134,0.50210565,0.3971565,0.47586533,0.46915773,0.5627982
-jvs059,0.50828254,0.70228535,0.64976215,0.5849072,0.57743466,0.46244708,0.48962906,0.63987124,0.46036446,0.5779625,0.5292309,0.4528036,0.6946316,0.61196744,0.6300368,0.5735779,0.39643177,0.54758096,0.4425485,0.5806042,0.5108403,0.46609232,0.49272445,0.50314015,0.53315955,0.5017655,0.7097233,0.46465904,0.6261822,1.0,0.47363842,0.4042724,0.4125133,0.6030761,0.6539776,0.41949913,0.5247196,0.5415728,0.59092957,0.4969476,0.6582071,0.49740776,0.7013761,0.5929009,0.54847395,0.6463309,0.6293924,0.59122396,0.4026495,0.5886659,0.5557094,0.70287436
-jvs060,0.35170403,0.39507753,0.53337026,0.55763644,0.3859934,0.41842747,0.35707304,0.5263498,0.35195145,0.45915043,0.55057853,0.40421128,0.48666653,0.39378312,0.40163124,0.53141725,0.30591968,0.42660597,0.36507282,0.502963,0.64931273,0.35964027,0.47275108,0.5716222,0.45786414,0.48944226,0.5431362,0.59685,0.466206,0.47363842,1.0,0.34923798,0.3018268,0.46913865,0.3997513,0.38287824,0.57719684,0.49721327,0.48483622,0.35082924,0.45821548,0.40972003,0.47876602,0.40460014,0.40561488,0.42322016,0.52066135,0.38441297,0.65914875,0.38297188,0.5568976,0.56903887
-jvs061,0.5055648,0.41327146,0.41031662,0.47264278,0.39955658,0.5169988,0.3688106,0.3707524,0.4497699,0.44061932,0.40530664,0.5751063,0.45519394,0.47131792,0.3980623,0.3725041,0.44674134,0.5460109,0.49810365,0.46926314,0.4481711,0.47179002,0.3632309,0.3958082,0.43939808,0.58554286,0.4038695,0.37626868,0.49598676,0.4042724,0.34923798,1.0,0.35503754,0.39924347,0.36297852,0.4763308,0.46716946,0.51850104,0.56484747,0.36036304,0.42802888,0.39949167,0.39517668,0.3647903,0.43708265,0.47267443,0.41126454,0.39029738,0.32452703,0.3557567,0.42749077,0.4585759
-jvs062,0.40001088,0.411887,0.35082707,0.43211946,0.41177377,0.34554395,0.4247494,0.40989795,0.42054567,0.46848992,0.2942688,0.33728257,0.3689639,0.50088066,0.5614425,0.5110304,0.606377,0.45815846,0.4939715,0.37315232,0.3200521,0.72429955,0.43621868,0.30711612,0.37480846,0.40268746,0.3571774,0.4114959,0.39324814,0.4125133,0.3018268,0.35503754,1.0,0.45629126,0.4421898,0.4071695,0.37312773,0.37673286,0.33734587,0.39613038,0.37936908,0.47889233,0.42693996,0.36795485,0.4970242,0.32509416,0.3319788,0.55405587,0.33535397,0.5305651,0.32532313,0.43747216
-jvs063,0.42413616,0.57706344,0.4733587,0.49715483,0.4058117,0.41822818,0.38971823,0.5029082,0.37493312,0.45308226,0.40786725,0.40333053,0.47358063,0.4850396,0.5827714,0.71539664,0.40012035,0.5326689,0.5341726,0.5846971,0.49066693,0.49804705,0.59222895,0.46327415,0.6202042,0.46528977,0.5639185,0.5831123,0.47242573,0.6030761,0.46913865,0.39924347,0.45629126,1.0,0.68745655,0.5698505,0.4885837,0.48411715,0.47331157,0.35667658,0.68637455,0.667968,0.5710746,0.60793287,0.55437803,0.4704901,0.44477665,0.53657764,0.41787273,0.6162934,0.56396365,0.67033964
-jvs064,0.434583,0.6241211,0.46263626,0.47616988,0.44435894,0.4074781,0.47897547,0.5343903,0.39217633,0.47455117,0.38355616,0.37144047,0.5182079,0.5550624,0.6588543,0.6018276,0.41471267,0.54253393,0.4755859,0.50613075,0.41034168,0.47251832,0.4863267,0.4201418,0.4864325,0.401654,0.50628376,0.4337253,0.506378,0.6539776,0.3997513,0.36297852,0.4421898,0.68745655,1.0,0.44540465,0.4292258,0.44527298,0.45015526,0.3681287,0.67958456,0.618023,0.6766571,0.6101015,0.57150203,0.47084087,0.43332222,0.6034587,0.34688896,0.74373823,0.49570495,0.57988405
-jvs065,0.35263893,0.46159226,0.3955815,0.4006215,0.36273277,0.47965035,0.31888577,0.34918395,0.39790794,0.39375398,0.3679209,0.4748659,0.38484582,0.41017365,0.40712515,0.49347037,0.40688106,0.43369785,0.7023848,0.60348,0.4469831,0.46152282,0.5718636,0.4565159,0.6487411,0.516673,0.43159276,0.48722994,0.37627658,0.41949913,0.38287824,0.4763308,0.4071695,0.5698505,0.44540465,1.0,0.504272,0.5087066,0.43835828,0.32683006,0.5395167,0.59004533,0.4153405,0.51843816,0.5407651,0.3813065,0.38562545,0.44963947,0.3923701,0.44263613,0.5411426,0.537774
-jvs066,0.38992307,0.47777793,0.60508347,0.56239295,0.5347121,0.66872716,0.42537645,0.4800817,0.5273428,0.5768333,0.6071101,0.57584286,0.5855028,0.5055448,0.43867785,0.52602863,0.41703713,0.46871522,0.5119412,0.71239084,0.6180745,0.44469672,0.6026654,0.73243475,0.592034,0.7270997,0.5830487,0.512811,0.50005776,0.5247196,0.57719684,0.46716946,0.37312773,0.4885837,0.4292258,0.504272,1.0,0.7037784,0.61881286,0.4934957,0.5373057,0.49465486,0.5413235,0.4826689,0.57954943,0.46773115,0.644179,0.51467365,0.5859361,0.44806087,0.67733544,0.68972343
-jvs067,0.4730869,0.5156665,0.677058,0.5941453,0.5647744,0.6095532,0.43807122,0.50612396,0.58936113,0.6208561,0.6691931,0.75798947,0.60733914,0.53642356,0.4758789,0.47465783,0.41954473,0.50643235,0.5609456,0.68862665,0.64983875,0.46886548,0.49419048,0.6766569,0.5431906,0.73685575,0.5749268,0.47423273,0.5571766,0.5415728,0.49721327,0.51850104,0.37673286,0.48411715,0.44527298,0.5087066,0.7037784,1.0,0.620668,0.51879525,0.5273113,0.4782608,0.5404712,0.508116,0.5502814,0.5360304,0.6274886,0.50138634,0.49013856,0.4476216,0.6447947,0.63348055
-jvs069,0.5055683,0.5149473,0.60017717,0.5730849,0.5165252,0.599681,0.42663547,0.4936648,0.46986923,0.52996707,0.595667,0.57050806,0.6828462,0.5337572,0.4590131,0.4535916,0.39005005,0.5565732,0.4380429,0.61744326,0.58874255,0.4247019,0.44769162,0.5643076,0.5423077,0.6471635,0.63005364,0.42833957,0.6082127,0.59092957,0.48483622,0.56484747,0.33734587,0.47331157,0.45015526,0.43835828,0.61881286,0.620668,1.0,0.46619818,0.56341696,0.43645343,0.54443717,0.45517272,0.49477696,0.65673196,0.6502303,0.4650283,0.40220702,0.42628136,0.5929904,0.6381004
-jvs072,0.41780445,0.4520729,0.56646585,0.48369807,0.71953636,0.44801638,0.4480199,0.4582761,0.5981908,0.6153208,0.50207,0.4738549,0.5413201,0.5274153,0.4461741,0.3868832,0.40661216,0.38989672,0.38760367,0.45136878,0.40521288,0.43110687,0.39794508,0.438661,0.3882587,0.517032,0.4834987,0.34344533,0.46844575,0.4969476,0.35082924,0.36036304,0.39613038,0.35667658,0.3681287,0.32683006,0.4934957,0.51879525,0.46619818,1.0,0.38242447,0.34897524,0.46465963,0.38498765,0.46081594,0.44679013,0.5801756,0.5085347,0.37473258,0.40639406,0.39832744,0.48445335
-jvs082,0.40977538,0.66072404,0.5141954,0.4758965,0.46265224,0.5201656,0.42728227,0.4804066,0.41879305,0.4688697,0.45034704,0.44627178,0.5657794,0.5282158,0.5191709,0.5728479,0.38955426,0.51478636,0.5159125,0.67325383,0.48444796,0.42969194,0.5677248,0.52972305,0.64877564,0.48484635,0.5884991,0.459997,0.5054995,0.6582071,0.45821548,0.42802888,0.37936908,0.68637455,0.67958456,0.5395167,0.5373057,0.5273113,0.56341696,0.38242447,1.0,0.61523074,0.63453203,0.7035168,0.615586,0.5261133,0.5176102,0.56303376,0.38929114,0.5886832,0.66380423,0.6854591
-jvs083,0.37062833,0.4820598,0.4094473,0.44630417,0.39954183,0.47584495,0.42833978,0.43307796,0.4017118,0.45188707,0.36395857,0.39605752,0.44456744,0.49077907,0.5419848,0.63245636,0.48008785,0.5187031,0.6112525,0.5645579,0.42444962,0.5129725,0.61784095,0.4671661,0.54955167,0.45505086,0.4493512,0.4744955,0.42151457,0.49740776,0.40972003,0.39949167,0.47889233,0.667968,0.618023,0.59004533,0.49465486,0.4782608,0.43645343,0.34897524,0.61523074,1.0,0.57798374,0.5323817,0.65954876,0.3781956,0.3934143,0.5951606,0.39522853,0.6764979,0.5393089,0.5838853
-jvs084,0.45870715,0.5783196,0.5691284,0.5848115,0.5634752,0.5114403,0.61361355,0.6383134,0.48422027,0.61852324,0.48867488,0.43458036,0.68984526,0.65668356,0.65404344,0.5952801,0.45891008,0.58602744,0.4684637,0.5574868,0.47967035,0.4847577,0.50717956,0.5278115,0.47693416,0.48373672,0.5602257,0.43924782,0.6058019,0.7013761,0.47876602,0.39517668,0.42693996,0.5710746,0.6766571,0.4153405,0.5413235,0.5404712,0.54443717,0.46465963,0.63453203,0.57798374,1.0,0.5425055,0.62999976,0.5036739,0.5482512,0.67100286,0.41829824,0.6915998,0.5569115,0.6472399
-jvs085,0.36674196,0.7128247,0.5098971,0.42295456,0.4680131,0.45218247,0.3896251,0.44267792,0.43169853,0.45012814,0.430389,0.44090953,0.4940592,0.4858045,0.47474095,0.5083156,0.35152364,0.41584185,0.5189972,0.6150545,0.43570313,0.3973625,0.5302414,0.4899999,0.58713645,0.43874758,0.5285924,0.42895836,0.4455726,0.5929009,0.40460014,0.3647903,0.36795485,0.60793287,0.6101015,0.51843816,0.4826689,0.508116,0.45517272,0.38498765,0.7035168,0.5323817,0.5425055,1.0,0.57354426,0.47330445,0.48996368,0.5353185,0.37754014,0.53537875,0.58922017,0.58775985
-jvs090,0.38923573,0.5704388,0.47830066,0.48335811,0.5557681,0.61250174,0.53465545,0.45928702,0.5651839,0.56950253,0.41528112,0.46818468,0.5447263,0.63359505,0.5410362,0.56920165,0.5634189,0.50565886,0.63589793,0.6092435,0.42093927,0.53843004,0.62074494,0.50617194,0.5458444,0.52878165,0.4729557,0.4295212,0.48237205,0.54847395,0.40561488,0.43708265,0.4970242,0.55437803,0.57150203,0.5407651,0.57954943,0.5502814,0.49477696,0.46081594,0.615586,0.65954876,0.62999976,0.57354426,1.0,0.4165805,0.48590505,0.77398646,0.4169692,0.652602,0.54633987,0.61712503
-jvs091,0.5937911,0.58015513,0.62379676,0.55036384,0.49535924,0.42881036,0.39266184,0.53010964,0.42130813,0.49367574,0.56320316,0.51159066,0.6261553,0.508122,0.48557946,0.41985673,0.3330408,0.5200973,0.3883097,0.5145247,0.53524834,0.4007134,0.3716781,0.45261782,0.47279778,0.5112167,0.6442971,0.40506035,0.6363261,0.6463309,0.42322016,0.47267443,0.32509416,0.4704901,0.47084087,0.3813065,0.46773115,0.5360304,0.65673196,0.44679013,0.5261133,0.3781956,0.5036739,0.47330445,0.4165805,1.0,0.6009895,0.42231956,0.3428142,0.4078445,0.4949899,0.5617886
-jvs092,0.43374446,0.54633373,0.78269815,0.5692747,0.6322663,0.5325173,0.43132606,0.54111445,0.5144701,0.5918875,0.7207073,0.53984153,0.70445067,0.5236852,0.44777423,0.45723522,0.35077265,0.4413131,0.40215224,0.60114294,0.5769179,0.3911699,0.4655659,0.611476,0.50864476,0.59759635,0.69043213,0.43471602,0.568134,0.6293924,0.52066135,0.41126454,0.3319788,0.44477665,0.43332222,0.38562545,0.644179,0.6274886,0.6502303,0.5801756,0.5176102,0.3934143,0.5482512,0.48996368,0.48590505,0.6009895,1.0,0.48424935,0.47102228,0.41994777,0.57942134,0.639016
-jvs093,0.41313696,0.580551,0.48527485,0.49977562,0.6038404,0.51403916,0.59605086,0.50722545,0.55655843,0.6101458,0.403589,0.42138252,0.5594211,0.69330096,0.62406075,0.5776441,0.5746961,0.51043206,0.54329973,0.5291737,0.39351863,0.56679344,0.5572898,0.45173055,0.47964278,0.48179665,0.47687873,0.41226637,0.50210565,0.59122396,0.38441297,0.39029738,0.55405587,0.53657764,0.6034587,0.44963947,0.51467365,0.50138634,0.4650283,0.5085347,0.56303376,0.5951606,0.67100286,0.5353185,0.77398646,0.42231956,0.48424935,1.0,0.39244628,0.73169994,0.47541538,0.5919642
-jvs094,0.30763423,0.36113253,0.4837551,0.5042609,0.3946383,0.41145417,0.34383604,0.45479885,0.3882776,0.47095886,0.48794624,0.4042843,0.41738427,0.37863564,0.37171054,0.5097078,0.33010462,0.36687896,0.39354292,0.47229403,0.54254717,0.38045937,0.50602615,0.53157467,0.43048838,0.49991256,0.45386034,0.5941264,0.3971565,0.4026495,0.65914875,0.32452703,0.33535397,0.41787273,0.34688896,0.3923701,0.5859361,0.49013856,0.40220702,0.37473258,0.38929114,0.39522853,0.41829824,0.37754014,0.4169692,0.3428142,0.47102228,0.39244628,1.0,0.36345607,0.48406836,0.5131443
-jvs095,0.40986836,0.5473224,0.44140765,0.47634295,0.4747711,0.43066734,0.5358553,0.5161939,0.43199185,0.5162096,0.3675513,0.3670197,0.50284225,0.59040064,0.68786836,0.627041,0.5014437,0.5337609,0.5079459,0.49345678,0.38629237,0.53573865,0.52893955,0.42026368,0.46339458,0.4157314,0.46513227,0.4243095,0.47586533,0.5886659,0.38297188,0.3557567,0.5305651,0.6162934,0.74373823,0.44263613,0.44806087,0.4476216,0.42628136,0.40639406,0.5886832,0.6764979,0.6915998,0.53537875,0.652602,0.4078445,0.41994777,0.73169994,0.36345607,1.0,0.46595594,0.5679806
-jvs096,0.37400877,0.5174066,0.57797927,0.48900142,0.45138618,0.5758334,0.37820774,0.4584564,0.42850417,0.47398618,0.56997377,0.5260558,0.5504863,0.45199,0.43184367,0.5178322,0.346393,0.45456988,0.50086063,0.8085976,0.62167025,0.38395068,0.5819298,0.76061493,0.6650221,0.56767565,0.61539906,0.4916092,0.46915773,0.5557094,0.5568976,0.42749077,0.32532313,0.56396365,0.49570495,0.5411426,0.67733544,0.6447947,0.5929904,0.39832744,0.66380423,0.5393089,0.5569115,0.58922017,0.54633987,0.4949899,0.57942134,0.47541538,0.48406836,0.46595594,1.0,0.68615794
-VOICEACTRESS100_001,0.46006167,0.6057587,0.6358979,0.60909736,0.53700763,0.54990536,0.44624665,0.57088345,0.47732845,0.57909554,0.5610101,0.5108592,0.62868094,0.56460774,0.56570673,0.6716561,0.4291511,0.5524034,0.5300679,0.7401001,0.6133621,0.50552917,0.65071297,0.6171123,0.68676335,0.63120115,0.7353094,0.5854786,0.5627982,0.70287436,0.56903887,0.4585759,0.43747216,0.67033964,0.57988405,0.537774,0.68972343,0.63348055,0.6381004,0.48445335,0.6854591,0.5838853,0.6472399,0.58775985,0.61712503,0.5617886,0.639016,0.5919642,0.5131443,0.5679806,0.68615794,1.0
diff --git a/Speaker-Embeddings/preprocess.py b/Speaker-Embeddings/preprocess.py
deleted file mode 100755
index ebc94dc..0000000
--- a/Speaker-Embeddings/preprocess.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import glob
-import os
-import librosa
-from pysptk import conversion
-import pyworld as pw
-import numpy as np
-import pandas as pd
-from hparam import hparam as hp
-import warnings
-warnings.simplefilter('ignore')
-
-
-
-def get_speakers_dict():
-    genders_dict = {}
-    genders = "male female".split()
-    for gender in genders:
-        csv_path = hp.data.sim_csv_path.format(gender)
-        df = pd.read_csv(csv_path, header=None, index_col=0)
-        speakers_dict = {speaker: index
-                         for index, speaker in enumerate(df.index)}
-        genders_dict[gender] = speakers_dict
-    return genders_dict
-
-def sp2mc(sp, order=39, alpha=0.41):   # alpha is all-pass constant
-    mcep = conversion.sp2mc(sp, order, alpha)
-    return mcep
-
-def get_para(data, fs):
-    _fo, _time = pw.dio(data, fs)               # 
-    fo = pw.stonemask(data, _fo, _time, fs)     # 
-    sp = pw.cheaptrick(data, fo, _time, fs)     # 
-    mcep = sp2mc(sp)
-    return fo, mcep
-
-def wav_to_mcep(audio_path):
-    mceps = []
-    for i, utter_path in enumerate(audio_path):
-        wav, source_sr = librosa.load(utter_path, sr=None)
-        # Resample the wav to 16kHz
-        wav = librosa.resample(wav, source_sr, hp.data.sr)
-        wav = wav.astype(np.float)
-
-        fo, mcep = get_para(wav, fs=hp.data.sr)
-
-        # remove silence using fo info
-        mask = fo.astype(np.bool)
-        mcep = mcep[mask, 1:]
-        if mcep.shape[0] < 50:
-            print("remove {} because of less than 50 frames.".format(utter_path))
-
-        mceps.append(mcep)
-    return mceps
-
-def main():
-    print("start text independent utterance feature extraction...\n")
-    os.makedirs(hp.data.nonpara_path, exist_ok=True)   # make folder to save train file
-    os.makedirs(hp.data.parallel_path, exist_ok=True)    # make folder to save test file
-
-    genders_dict = get_speakers_dict()
-    n_totals = {gender: len(genders_dict[gender])
-               for gender in genders_dict.keys()}
-    n_trains = {gender: (n_totals[gender]//10)*9
-               for gender in genders_dict.keys()} # split total data 90% train and 10% test
-
-    for gender in genders_dict.keys():
-        print("total {} speaker number : {}".format(gender, n_totals[gender]))
-        print("train : {}, test : {}\n".format(
-            n_trains[gender], n_totals[gender] - n_trains[gender]))
-
-    for gender in genders_dict.keys():
-        speakers = genders_dict[gender]
-        for i, speaker in enumerate(speakers.keys()):
-            print("%dth speaker processing..." % (i + 1))
-            for dir, contents, save_path in zip([hp.raw_nonpara_data, hp.raw_parallel_data],
-                                     [hp.data.non_para_contents, hp.data.parallel_contents],
-                                     [hp.data.nonpara_path, hp.data.parallel_path]):
-                speaker_path = os.path.join(dir, speaker, contents, '*.wav')
-                audio_path = glob.glob(speaker_path)
-                mceps = wav_to_mcep(audio_path)
-
-                # save mcep as numpy file
-                save_dir = os.path.join(save_path, speaker)
-                os.makedirs(save_dir, exist_ok=True)
-                fn = os.path.join(save_dir, "utter{:02d}.npy")
-                for i, mcep in enumerate(mceps, start=1):
-                    np.save(fn.format(i), mcep)
-
-
-
-if __name__ == "__main__":
-    main()
\ No newline at end of file
diff --git a/Speaker-Embeddings/train.py b/Speaker-Embeddings/train.py
deleted file mode 100755
index f897aa9..0000000
--- a/Speaker-Embeddings/train.py
+++ /dev/null
@@ -1,94 +0,0 @@
-import os
-import sys
-
-import torch
-import matplotlib.pyplot as plt
-import warnings
-warnings.simplefilter('ignore')
-from torch.utils.data import DataLoader
-
-from hparam import hparam as hp
-from dataloader import JVSNonparaTrain, JVSNonparaVal
-from model import FFNet, SimMatrixLoss
-from preprocess import get_speakers_dict
-
-
-
-def train(gender="female"):
-    device = torch.device(hp.device)
-
-    net = FFNet().to(device)
-    if hp.train.restore:
-        net.load_state_dict(torch.load(model_path=None))
-
-    sim_csv_path = hp.data.sim_csv_path.format(gender)
-    spekers_dict = get_speakers_dict()[gender]
-
-    train_dataset = JVSNonparaTrain(spekers_dict, device, net)
-    train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False,
-                              num_workers=hp.train.num_workers, drop_last=True)
-    val_dataset = JVSNonparaVal(spekers_dict, device, net)
-    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False,
-                              num_workers=hp.test.num_workers, drop_last=True)
-
-    simmat_loss = SimMatrixLoss(device, sim_csv_path=sim_csv_path)
-    optimizer = torch.optim.Adagrad(net.parameters(), lr=hp.train.lr)
-    
-    os.makedirs(hp.train.checkpoint_dir, exist_ok=True)
-    
-    net.train()
-    iteration = 0
-    print('=' * 30)
-    losses = []
-    for i in range(hp.train.iteration):
-        total_loss = 0
-        for batch_id, d_vectors in enumerate(train_loader):
-            #gradient accumulates
-            optimizer.zero_grad()
-
-            #get loss, call backward, step optimizer
-            loss = simmat_loss(d_vectors)
-
-            loss.backward()
-            optimizer.step()
-            total_loss = total_loss + loss
-            losses.append(loss.item())
-            iteration += 1
-            if (batch_id + 1) % hp.train.log_interval == 0:
-                mesg = f"Iteration:{iteration}\t" \
-                       f"Loss:{loss:.4f}\tTotal Loss:{total_loss / (batch_id + 1):.4f}"
-                print(mesg, end="\t")
-
-        for batch_id, d_vectors in enumerate(val_loader):
-            with torch.no_grad():
-                loss = simmat_loss(d_vectors)
-                if (batch_id + 1) % hp.train.log_interval == 0:
-                    print(f"Val Loss:{loss:.4f}\t")
-
-        if hp.train.checkpoint_dir is not None and (i + 1) % hp.train.checkpoint_interval == 0:
-            net.eval().cpu()
-            ckpt_model_filename = f"ckpt_epoch_{i+1}.pth"
-            ckpt_model_path = os.path.join(hp.train.checkpoint_dir, ckpt_model_filename)
-            torch.save(net.state_dict(), ckpt_model_path)
-            net.to(device).train()
-
-    #save model
-    net.eval().cpu()
-    save_model_filename = f"final_epoch_{i + 1}.model"
-    save_model_path = os.path.join(hp.train.checkpoint_dir, save_model_filename)
-    torch.save(net.state_dict(), save_model_path)
-    
-    print("\nDone, trained model saved at", save_model_path)
-    plt.plot(losses)
-    plt.xlabel("Iteration")
-    plt.ylabel("Loss")
-    plt.show()
-
-            
-
-if __name__=="__main__":
-    if len(sys.argv) > 1:
-        gender = sys.argv[1]
-    else:
-        sys.exit()
-    train(gender=gender)
\ No newline at end of file
